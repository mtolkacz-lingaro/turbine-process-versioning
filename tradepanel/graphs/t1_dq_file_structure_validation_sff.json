{
  "applicationName": "TURBINE_INTERNAL",
  "nodes": [
    {
      "operationName": "dummy",
      "jsonSpecification": "{\n  \"active\": \"true\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"manualSchema\": \"true\",\n  \"transformations\": [\n    {\n      \"columnType\": \"string\",\n      \"columnName\": \"test\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_dummy\",\n      \"cache\": \"none\"\n    }\n  ]\n}",
      "operationVersionName": "CreateSchema",
      "overridableIndicator": false
    },
    {
      "operationName": "Load MM_TIME_PERD_FDIM_VW",
      "predecessorName": "dummy",
      "jsonSpecification": "{\n  \"active\": \"true\",\n  \"fileType\": \"parquet\",\n  \"inferSchema\": \"false\",\n  \"path\": \"refined/NNIT/tradepanel/prod-tp-lightrefined/MM_TIME_PERD_FDIM_VW//\",\n  \"addInputFileName\": \"false\",\n  \"semaphoreOption\": \"shared\",\n  \"createIfNotExist\": \"false\",\n  \"mergeSchema\": \"false\",\n  \"milestone\": \"true\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_time_perd_fdim_vw\",\n      \"cache\": \"materialize\"\n    }\n  ]\n}",
      "operationVersionName": "FileLoaderTabular",
      "overridableIndicator": false
    },
    {
      "operationName": "Release MM_TIME_PERD_FDIM_VW",
      "predecessorName": "Load MM_TIME_PERD_FDIM_VW",
      "jsonSpecification": "{\n  \"active\": \"true\",\n  \"actionType\": \"release\",\n  \"itemType\": \"path\",\n  \"itemPath\": \"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_TIME_PERD_FDIM_VW/\"\n}",
      "operationVersionName": "SemaphoreOperation",
      "overridableIndicator": false
    },
    {
      "operationName": "File Structure Validations",
      "predecessorName": "Release MM_TIME_PERD_FDIM_VW",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"customCode\": \"spark = self.spark_session\\nmyLogger = self.log\\nfrom IPython import get_ipython\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\n\\n\\ntier1_prod_mtrlz_tbl = dict_all_dfs['tier1_prod_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_measr_mtrlz_tbl = dict_all_dfs['tier1_measr_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_mkt_mtrlz_tbl = dict_all_dfs['tier1_mkt_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_time_mtrlz_tbl = dict_all_dfs['tier1_time_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_fct_mtrlz_tbl = dict_all_dfs['tier1_fct_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_fct_mtrlz_tbl2 = dict_all_dfs['tier1_fct_conv'][\\\"df_object\\\"]\\n\\n# Create views\\ntier1_prod_mtrlz_tbl.createOrReplaceTempView('tier1_prod_mtrlz_tbl')\\ntier1_measr_mtrlz_tbl.createOrReplaceTempView('tier1_measr_mtrlz_tbl')\\ntier1_mkt_mtrlz_tbl.createOrReplaceTempView('tier1_mkt_mtrlz_tbl')\\ntier1_time_mtrlz_tbl.createOrReplaceTempView('tier1_time_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl.createOrReplaceTempView('tier1_fct_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl2.createOrReplaceTempView('tier1_fct_mtrlz_tbl2')\\n\\n# Define Variables\\nTIER1_VENDR_ID=\\\"<<VENDOR_ID>>\\\"\\nTIER1_FILE_PREFX=\\\"<<CONTRACT_CODE>>\\\"\\nTIER1_CNTRT_ID=<<CNTRT_ID>>\\nTIER1_RUN_ID=<<PROCESS_RUN_KEY>>\\n\\n# Reading tables from postgres\\n\\n\\n\\njdbcDF1 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CATEG_STRCT_ATTR_ASSOC_VW\\\")\\njdbcDF1.createOrReplaceTempView(\\\"mm_categ_strct_attr_assoc_vw\\\")\\n\\njdbcDF2 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_TIME_PERD_TYPE_ASSOC\\\")\\njdbcDF2.createOrReplaceTempView(\\\"mm_cntrt_time_perd_type_assoc\\\")\\n\\njdbcDF3 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_CATEG_ASSOC\\\")\\njdbcDF3.createOrReplaceTempView(\\\"mm_cntrt_categ_assoc\\\")\\n\\ndf_10 = spark.read.format('parquet').option('header', True).load(f'/mnt/bf/unrefined/adw-hhp-unrefined-bf/MM_TIME_PERD_FDIM_VW/')\\ndf_10.createOrReplaceTempView('mm_time_perd_fdim_vw')\\n\\n# Validations\\n\\n##prod_data_exist\\nsql1=\\\"select extrn_code as dq1_extrn_code,extrn_name as dq1_extrn_name,line_num  as dq1_line_num from tier1_prod_mtrlz_tbl limit 100\\\"\\ndf_prd_data_exist=spark.sql(sql1)\\n##measr_data_exist\\nsql2=\\\"select extrn_code as dq2_extrn_code,extrn_name as dq2_extrn_name,line_num as dq2_line_num from tier1_measr_mtrlz_tbl limit 100\\\"\\ndf_measr_data_exist=spark.sql(sql2)\\n##market_data_exist\\nsql3=\\\"select extrn_code dq3_extrn_code,attr_code_list dq3_attr_code_list,extrn_name dq3_extrn_name,line_num dq3_line_num from tier1_mkt_mtrlz_tbl limit 100\\\"\\ndf_mkt_mtrlz=spark.sql(sql3)\\n## Time data exist\\nsql4=\\\"select mm_time_perd_id as dq4_mm_time_perd_id,extrn_code as dq4_extrn_code,extrn_name as dq4_extrn_name,line_num  as dq4_line_num from tier1_time_mtrlz_tbl limit 100\\\"\\ndf_time_mtrlz=spark.sql(sql4)\\n##Fact uses supplier time tag not defined in the reference part\\nsql5=\\\"\\\"\\\"SELECT DISTINCT A.Time_extrn_Code AS dq5_time FROM  tier1_fct_mtrlz_tbl A \\nLEFT JOIN tier1_time_mtrlz_tbl D ON A.Time_extrn_code = D.EXTRN_CODE WHERE D.EXTRN_CODE IS NULL limit 100\\\"\\\"\\\"\\ndf_time_tag=spark.sql(sql5)\\n##Fact uses supplier market tag not defined in the reference part\\nsql6=\\\"\\\"\\\"SELECT DISTINCT A.MKT_EXTRN_CODE AS dq6_market FROM tier1_fct_mtrlz_tbl A LEFT JOIN tier1_mkt_mtrlz_tbl B ON A.MKT_EXTRN_CODE= B.EXTRN_CODE  WHERE B.EXTRN_CODE IS NULL  limit 100\\\"\\\"\\\"\\ndf_mkt_tag=spark.sql(sql6)\\n##Check whether in the reference part of the file multiple lines with the same product tag exist\\nsql7=\\\"\\\"\\\"SELECT DISTINCT A.Prod_extrn_Code AS dq7_prod FROM tier1_fct_mtrlz_tbl A LEFT JOIN tier1_prod_mtrlz_tbl C ON A.Prod_extrn_code = C.EXTRN_CODE  WHERE C.EXTRN_CODE IS NULL limit 100\\\"\\\"\\\"\\ndf_prod_tag=spark.sql(sql7)\\n##Check whether in the reference part of the file multiple lines with the same product attribute exist\\nsql8=\\\"\\\"\\\"WITH PROD_LVL AS (SELECT  * FROM mm_categ_strct_attr_assoc_vw ),\\nSRC AS (\\nSELECT * FROM tier1_prod_mtrlz_tbl input\\n LEFT OUTER JOIN PROD_LVL ON input.ATTR_CODE_1 = PROD_LVL.CATEG_ID AND input.ATTR_CODE_0 = cast(PROD_LVL.STRCT_NUM as string) AND input.LVL_NUM = PROD_LVL.LVL_NUM                            \\n)\\nSELECT A.EXTRN_PROD_ATTR_VAL_LIST as dq8_extrn_prod_attr_val_list FROM SRC A JOIN SRC B \\nON A.EXTRN_PROD_ATTR_VAL_LIST = B.EXTRN_PROD_ATTR_VAL_LIST AND A.LINE_NUM != B.LINE_NUM AND A.ATTR_NAME <> 'ITEM' limit 100\\\"\\\"\\\"\\ndf_prod_attr_tag=spark.sql(sql8)\\n##Check whether in the reference part of the file multiple lines with the same measure tag exist(Found in rprt prc)\\nsql9=\\\"\\\"\\\"SELECT DISTINCT A.LINE_NUM AS dq9_line_num,(A.EXTRN_CODE) AS dq9_extrn_code,(A.EXTRN_NAME) AS dq9_extrn_name FROM tier1_measr_mtrlz_tbl A JOIN tier1_measr_mtrlz_tbl B ON A.EXTRN_CODE = B.EXTRN_CODE AND A.LINE_NUM != B.LINE_NUM\\\"\\\"\\\"\\ndf_measr_tag=spark.sql(sql9)\\n##Check if values of all facts delivered are valid numbers or are NA or blanks\\nsql10=\\\"\\\"\\\"SELECT mkt_extrn_code as dq10_mkt_extrn_code,prod_extrn_code as dq10_prod_extrn_code,time_extrn_code as dq10_time_extrn_code, fact_amt_1 as dq10_fact_amt_1 FROM tier1_fct_mtrlz_tbl limit 100\\\"\\\"\\\"\\ndf_vld_NA=spark.sql(sql10)\\n##The maximum number of measures in the file in one fact line is 20\\n#sql11=\\\"\\\"\\\"SELECT mkt_extrn_code as dq11_mkt_extrn_code,prod_extrn_code as dq11_prod_extrn_code,time_extrn_code as dq11_time_extrn_code, OTHER_FCT_DATA as dq11_fact_amt FROM tier1_fct_mtrlz_tbl2 WHERE OTHER_FCT_DATA IS NOT NULL LIMIT 100\\\"\\\"\\\"\\n#df_measr_fct_line=spark.sql(sql11)\\n##Tests whether at least a single line with fact dimension is available\\n#sql12=\\\"\\\"\\\"SELECT mkt_extrn_code as dq12_mkt_extrn_code,prod_extrn_code as dq12_prod_extrn_code,time_extrn_code as dq12_time_extrn_code FROM tier1_fct_mtrlz_tbl2 WHERE OTHER_FCT_DATA IS NOT NULL LIMIT 100\\\"\\\"\\\"\\n#df_fct_mtrlz=spark.sql(sql12)\\n##Number of fact lines per each combination of tags should equal total number of measures in reference part divided by expected number of measures in a single fact line i.e. by 20\\nsql13=\\\"\\\"\\\"SELECT extrn_code as dq13_extrn_code,attr_code_list as dq13_attr_code_list ,mkt_match_attr_list as dq13_mkt_match_attr_list ,extrn_mkt_attr_val_list as dq13_extrn_mkt_attr_val_list,attr_code_0 as dq13_attr_code_0 FROM tier1_mkt_mtrlz_tbl WHERE (ATTR_CODE_0 <> '1' OR ATTR_CODE_0 IS NULL) AND STRCT_CODE NOT LIKE 'TP%' limit 100\\\"\\\"\\\"\\ndf_divi_measr=spark.sql(sql13)\\n##checks whether supplier tags for market dimensions in each fact line are defined in the reference part\\nsql14=\\\"\\\"\\\"SELECT DISTINCT A.LINE_NUM AS dq14_line_mkt, A.MKT_EXTRN_CODE AS dq14_mkt_extrn_code FROM tier1_fct_mtrlz_tbl2 A LEFT JOIN tier1_mkt_mtrlz_tbl B ON A.MKT_EXTRN_CODE = B.EXTRN_CODE WHERE B.EXTRN_CODE IS NULL limit 100\\\"\\\"\\\"\\ndf_multi_lines_mkt_tag=spark.sql(sql14)\\n###checks whether supplier tags for product dimension in each fact line are defined in the reference part\\nsql15=\\\"\\\"\\\"select a.prod_extrn_code as dq15_prod_extrn_code  from tier1_fct_mtrlz_tbl a left join tier1_prod_mtrlz_tbl c on a.prod_extrn_code = c.extrn_code where c.extrn_code is null  limit 100\\\"\\\"\\\"\\ndf_multilines_prod_tag=spark.sql(sql15)\\n##checks whether supplier tags for time dimension in each fact line are defined in the reference part\\nsql16=\\\"\\\"\\\"select time_extrn_code as dq16_time_extrn_code from tier1_fct_mtrlz_tbl left join tier1_time_mtrlz_tbl on  time_extrn_code==extrn_code where extrn_code is null limit 100\\\"\\\"\\\"\\ndf_multilines_time_tag=spark.sql(sql16)\\n##Delivered file format is correct vs. contract setup\\nsql17=\\\"\\\"\\\"WITH ret AS (SELECT line_num,attr_code_0 FROM tier1_prod_mtrlz_tbl WHERE NOT REGEXP_LIKE(attr_code_0, '^\\\\d+$')\\nUNION ALL\\nSELECT line_num,attr_code_0  FROM tier1_mkt_mtrlz_tbl WHERE NOT REGEXP_LIKE(attr_code_0, '^\\\\d+$') AND strct_code = 'LF_H1')    \\nselect line_num as dq17_line_num,attr_code_0 as dq17_attr_code_0 from ret limit 100\\\"\\\"\\\"\\ndf_crct_cntrct_setup=spark.sql(sql17)\\n##Tests whether category in the file is matching contract specification\\nsql18=f\\\"\\\"\\\"WITH c AS(SELECT categ_id FROM mm_cntrt_categ_assoc c WHERE cntrt_id ={TIER1_CNTRT_ID} ),\\nret AS(SELECT line_num, attr_code_1 AS file_categ FROM tier1_prod_mtrlz_tbl WHERE attr_code_1 NOT IN ( SELECT categ_id FROM c)) \\nSELECT line_num as dq18_line_num,(file_categ) as dq18_file_categ,(categ_id) AS dq18_spec_categ FROM ret, c \\\"\\\"\\\"\\ndf_file_match=spark.sql(sql18)\\n\\n# Combine Valiation Dataframes\\n\\n####################df_prod_attr_tag may thorugh error while executing \\nfrom pyspark.sql.functions import lit, row_number, monotonically_increasing_id, col, when\\nfrom pyspark.sql.window import Window\\nfrom pyspark.sql.types import *\\ncolumns = StructType([StructField('row_id', IntegerType(), True)])\\ndf_empty = spark.createDataFrame(data=[], schema=columns)\\n\\n\\ndf_prd_data_exist=df_prd_data_exist.withColumn('DQ1', lit('product data exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_measr_data_exist=df_measr_data_exist.withColumn('DQ2', lit('measure data exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_mkt_mtrlz=df_mkt_mtrlz.withColumn('DQ3', lit('market data exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_time_mtrlz=df_time_mtrlz.withColumn('DQ4', lit('time data exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_time_tag=df_time_tag.withColumn('DQ5', lit('time_tag exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_mkt_tag=df_mkt_tag.withColumn('DQ6', lit('market_tag exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_prod_tag=df_prod_tag.withColumn('DQ7', lit('product_tag exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_prod_attr_tag=df_prod_attr_tag.withColumn('DQ8', lit('product_tag exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_measr_tag=df_measr_tag.withColumn('DQ9', lit('measr_tag exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_vld_NA=df_vld_NA.withColumn('DQ10', lit('valid numbers or are NA or blanks exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\n# df_measr_fct_line=df_measr_fct_line.withColumn('DQ11', lit(' maximum number of measures in the file in one fact line is 20')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\n# df_fct_mtrlz=df_fct_mtrlz.withColumn('DQ12', lit(' fct data exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_divi_measr=df_divi_measr.withColumn('DQ13', lit('Number of fact lines matches number of measures in measure dimension exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_multi_lines_mkt_tag=df_multi_lines_mkt_tag.withColumn('DQ14', lit('Number of fact lines matches number of measures in measure dimension exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_multilines_prod_tag=df_multilines_prod_tag.withColumn('DQ15', lit('Number of fact lines matches number of measures in measure dimension exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_multilines_time_tag=df_multilines_time_tag.withColumn('DQ16', lit('Number of fact lines matches number of measures in measure dimension exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_crct_cntrct_setup=df_crct_cntrct_setup.withColumn('DQ17', lit('Number of fact lines matches number of measures in measure dimension exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\ndf_file_match=df_file_match.withColumn('DQ18', lit('Number of fact lines matches number of measures in measure dimension exist')).withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id())))\\n\\ndf_combine = df_measr_data_exist.join(df_prd_data_exist,['row_id'] , 'full').join(df_mkt_mtrlz,['row_id'] , 'full').join(df_time_mtrlz,['row_id'] , 'full').join(df_time_tag,['row_id'] , 'full').join(df_mkt_tag,['row_id'] , 'full').join(df_prod_tag,['row_id'] , 'full').join(df_prod_attr_tag,['row_id'] , 'full').join(df_measr_tag,['row_id'] , 'full').join(df_vld_NA,['row_id'] , 'full').join(df_divi_measr,['row_id'] , 'full').join(df_multi_lines_mkt_tag,['row_id'] , 'full').join(df_multilines_prod_tag,['row_id'] , 'full').join(df_multilines_time_tag,['row_id'] , 'full').join(df_crct_cntrct_setup,['row_id'] , 'full').join(df_file_match,['row_id'] , 'full').drop('row_id').withColumn(\\\"row_id\\\",row_number().over(Window.orderBy(monotonically_increasing_id()))).orderBy(col('row_id'))\\n\\n\\ndq1_columns=['DQ1','dq1_extrn_code','dq1_extrn_name','dq1_line_num']\\ndq2_columns=['DQ2','dq2_extrn_code','dq2_extrn_name','dq2_line_num']\\ndq3_columns=['DQ3','dq3_extrn_code','dq3_attr_code_list','dq3_extrn_name','dq3_line_num']\\ndq4_columns=['DQ4','dq4_mm_time_perd_id','dq4_extrn_code','dq4_extrn_name','dq4_line_num']\\ndq5_columns=['DQ5','dq5_time']\\ndq6_columns=['DQ6','dq6_market']\\ndq7_columns=['DQ7','dq7_prod']\\ndq8_columns=['DQ8','dq8_extrn_prod_attr_val_list']\\ndq9_columns=['DQ9','dq9_line_num','dq9_extrn_code','dq9_extrn_name']\\ndq10_columns=['DQ10','dq10_mkt_extrn_code','dq10_prod_extrn_code','dq10_time_extrn_code','dq10_fact_amt_1']\\n#dq11_columns=['DQ11','dq11_mkt_extrn_code','dq11_prod_extrn_code','dq11_time_extrn_code','dq11_fact_amt']\\n#dq12_columns=['DQ12','dq12_mkt_extrn_code','dq12_prod_extrn_code','dq12_time_extrn_code']\\ndq13_columns=['DQ13','dq13_extrn_code','dq13_attr_code_list','dq13_mkt_match_attr_list','dq13_extrn_mkt_attr_val_list','dq13_attr_code_0']\\ndq14_columns=['DQ14','dq14_line_mkt','dq14_mkt_extrn_code']\\ndq15_columns=['DQ15','dq15_prod_extrn_code']\\ndq16_columns=['DQ16','dq16_time_extrn_code']\\ndq17_columns=['DQ17','dq17_line_num','dq17_attr_code_0']\\ndq18_columns=['DQ18','dq18_line_num','dq18_file_categ','dq18_spec_categ']\\n\\n\\ncombined_cols = ['row_id']\\ndata = []\\n[combined_cols.append(i) for i in dq1_columns]\\n[combined_cols.append(i) for i in dq2_columns]\\n[combined_cols.append(i) for i in dq3_columns]\\n[combined_cols.append(i) for i in dq4_columns]\\n[combined_cols.append(i) for i in dq5_columns]\\n[combined_cols.append(i) for i in dq6_columns]\\n[combined_cols.append(i) for i in dq7_columns]\\n[combined_cols.append(i) for i in dq8_columns]\\n[combined_cols.append(i) for i in dq9_columns]\\n[combined_cols.append(i) for i in dq10_columns]\\n#[combined_cols.append(i) for i in dq11_columns]\\n#[combined_cols.append(i) for i in dq12_columns]\\n[combined_cols.append(i) for i in dq13_columns]\\n[combined_cols.append(i) for i in dq14_columns]\\n[combined_cols.append(i) for i in dq15_columns]\\n[combined_cols.append(i) for i in dq16_columns]\\n[combined_cols.append(i) for i in dq17_columns]\\n[combined_cols.append(i) for i in dq18_columns]\\n\\n\\n\\n\\ndq1_val=('dql_extrn_code','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Product Data Existence',100)\\ndata.append(dq1_val)\\ndq2_val=('dq2_extrn_code','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Measure Data Existence',100)\\ndata.append(dq2_val)\\ndq3_val=('dq3_attr_code_list','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Measure Data Existence',100)\\ndata.append(dq3_val)\\ndq4_val=('dq4_mm_time_perd_id','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Measure Data Existence',100)\\ndata.append(dq4_val)\\ndq5_val=('dq5_time','Data Existence KPI',\\\"\\\",\\\"\\\",'false','time tag data exist',100)\\ndata.append(dq5_val)\\ndq6_val=('dq6_market','Data Existence KPI',\\\"\\\",\\\"\\\",'false','market tag data exist',100)\\ndata.append(dq6_val)\\ndq7_val=('dq7_prod','Data Existence KPI',\\\"\\\",\\\"\\\",'false','market tag data exist',100)\\ndata.append(dq7_val)\\ndq8_val=('dq8_extrn_prod_attr_val_list','Data Existence KPI',\\\"\\\",\\\"\\\",'false','market tag data exist',100)\\ndata.append(dq8_val)\\ndq9_val=('dq9_line_num','Data Existence KPI',\\\"\\\",\\\"\\\",'false','market tag data exist',100)\\ndata.append(dq9_val)\\ndq10_val=('dq10_fact_amt_1','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Checking NA or Blanks Exist',100)\\ndata.append(dq10_val)\\n#dq11_val=('dq11_fact_amt','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Checking NA or Blanks Exist',100)\\n#data.append(dq11_val)\\n#dq12_val=('dq12_prod_extrn_code','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Single Fact lines  Data Existence',100)\\n#data.append(dq12_val)\\ndq13_val=('dq13_attr_code_0','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Expected number of single fact lines',100)\\ndata.append(dq13_val)\\ndq14_val=('dq14_mkt_extrn_code','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Market in each fact line exist',100)\\ndata.append(dq14_val)\\ndq15_val=('dq15_prod_extrn_code','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Product in each fact line data Existence',100)\\ndata.append(dq15_val)\\ndq16_val=('dq16_time_extrn_code','Data Existence KPI',\\\"\\\",\\\"\\\",'false','time dimension in each fact line Data Existence',100)\\ndata.append(dq16_val)\\ndq17_val=('dq17_attr_code_0','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Delivered file format correct vs contract setup',100)\\ndata.append(dq17_val)\\ndq18_val=('dq18_spec_categ','Data Existence KPI',\\\"\\\",\\\"\\\",'false','Delivered file format correct vs contract setup',100)\\ndata.append(dq18_val)\\n\\n\\ndf_combine = df_combine.select(*combined_cols)\\n\\n#Prepare KPI\\n\\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\\n\\nschema_for_kpi = StructType([ \\n    StructField(\\\"column\\\",StringType(),True),\\n    StructField(\\\"kpi_type\\\",StringType(),True),\\n    StructField(\\\"param_1\\\",StringType(),True),\\n    StructField(\\\"param_2\\\",StringType(),True),\\n    StructField(\\\"fail_on_error\\\",StringType(),True),\\n    StructField(\\\"check_description\\\",StringType(),True),\\n    StructField(\\\"target\\\",StringType(),True)\\n  ])\\n\\n\\ndf_file_struct_data = spark.createDataFrame(data, schema_for_kpi)\\n\\ndict_all_dfs['df_file_struct_data'] = {\\\"df_object\\\" :df_file_struct_data}\\ndf_output_dict['df_file_struct_data'] = df_file_struct_data\\n\\ndict_all_dfs['df_combine_file_struct'] = {\\\"df_object\\\" :df_combine}\\ndf_output_dict['df_combine_file_struct'] = df_combine\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"tier1_prod_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_measr_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_mkt_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_time_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_fct_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_fct_conv\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_file_struct_data\",\n      \"cache\": \"materialize\"\n    },\n    {\n      \"name\": \"df_combine_file_struct\",\n      \"cache\": \"materialize\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": false
    },
    {
      "operationName": "File Structure Validations - 1.1",
      "predecessorName": "File Structure Validations",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"customCode\": \"\\nspark = self.spark_session\\nmyLogger = self.log\\nfrom IPython import get_ipython\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\n\\nfrom pyspark.sql.functions import *\\n\\n#Variables\\n\\nTIER1_VENDR_ID=\\\"<<VENDOR_ID>>\\\"\\nTIER1_FILE_PREFX=\\\"<<CONTRACT_CODE>>\\\"\\nTIER1_CNTRT_ID=<<CNTRT_ID>>\\nTIER1_RUN_ID=<<PROCESS_RUN_KEY>>\\n\\npath = '/mnt/<@@PATH1@@>'\\n\\n# Reading tables from postgres\\n\\n\\n\\njdbcDF1 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CATEG_STRCT_ATTR_ASSOC_VW\\\")\\njdbcDF1.createOrReplaceTempView(\\\"mm_categ_strct_attr_assoc_vw\\\")\\n\\njdbcDF2 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_TIME_PERD_TYPE_ASSOC\\\")\\njdbcDF2.createOrReplaceTempView(\\\"mm_cntrt_time_perd_type_assoc\\\")\\n\\njdbcDF3 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_CATEG_ASSOC\\\")\\njdbcDF3.createOrReplaceTempView(\\\"mm_cntrt_categ_assoc\\\")\\n\\njdbcDF4 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_TIER_EXTND_VW\\\")\\njdbcDF4.createOrReplaceTempView(\\\"MM_CNTRT_TIER_EXTND_VW\\\")\\n\\nquery_mm_cntrt_tier1_atomic_vw = \\\"\\\"\\\"select * from MM_CNTRT_TIER_EXTND_VW \\nWHERE SRCE_SYS_ID=3\\nAND CNTRT_DATA_STTUS_NAME='Production'\\nAND CNTRT_STTUS_NAME='Active'\\nAND DATA_TIER='Tier 1'\\nAND DATA_LAYER='Atomic' \\\"\\\"\\\"\\nmm_cntrt_tier1_atomic_vw = spark.sql(query_mm_cntrt_tier1_atomic_vw)\\nmm_cntrt_tier1_atomic_vw.createOrReplaceTempView('mm_cntrt_tier1_atomic_vw')\\n\\njdbcDF5 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_TIME_PERD_ID_LKP\\\")\\njdbcDF5.createOrReplaceTempView(\\\"MM_TIME_PERD_ID_LKP\\\")\\n\\njdbcDF6 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_TIME_PERD_TYPE_ASSOC\\\").filter(f\\\"cntrt_id = {TIER1_CNTRT_ID}\\\")\\njdbcDF6.createOrReplaceTempView(\\\"MM_CNTRT_TIME_PERD_TYPE_ASSOC\\\")\\n\\ndf_10 = spark.read.format('parquet').option('header', True).load(f'{path}/MM_TIME_PERD_FDIM_VW/')\\ndf_10.createOrReplaceTempView('mm_time_perd_fdim_vw')\\n\\n#vDataframes from prior steps\\n\\ntier1_prod_mtrlz_tbl = dict_all_dfs['tier1_prod_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_measr_mtrlz_tbl = dict_all_dfs['tier1_measr_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_mkt_mtrlz_tbl = dict_all_dfs['tier1_mkt_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_time_mtrlz_tbl = dict_all_dfs['tier1_time_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_fct_mtrlz_tbl = dict_all_dfs['tier1_fct_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_fct_mtrlz_tbl2 = dict_all_dfs['tier1_fct_conv'][\\\"df_object\\\"]\\n\\n# Create views\\ntier1_prod_mtrlz_tbl.createOrReplaceTempView('tier1_prod_mtrlz_tbl')\\ntier1_measr_mtrlz_tbl.createOrReplaceTempView('tier1_measr_mtrlz_tbl')\\ntier1_mkt_mtrlz_tbl.createOrReplaceTempView('tier1_mkt_mtrlz_tbl')\\ntier1_time_mtrlz_tbl.createOrReplaceTempView('tier1_time_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl.createOrReplaceTempView('tier1_fct_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl.createOrReplaceTempView('tier1_fact_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl2.createOrReplaceTempView('tier1_fct_mtrlz_tbl2')\\n\\n# Validation work starts\\n\\n#1. Bad fact data format\\n\\n\\nrpt_query1 = \\\"\\\"\\\" SELECT \\n('Bad fact data format') DQ,\\nLINE_NUM, \\n\\tMKTEXT MKTEXT, \\n\\tMKTNAME MKTNAME, \\n\\tPRODEXT PRODEXT, \\n\\tPRODLIST PRODLIST, \\n\\tTIMEEXT TIMEEXT, \\n\\tTIMENAME TIMENAME,\\n\\terror_val error_val,\\n\\tMEASURE MEASURE \\nFROM (WITH ordm AS (\\nSELECT msr.*, ROW_NUMBER() OVER (ORDER BY LINE_NUM) rnm FROM TIER1_MEASR_MTRLZ_TBL msr \\n),\\nordf AS (\\nSELECT mfct.*, ROW_NUMBER() OVER (PARTITION BY MKT_EXTRN_CODE, PROD_EXTRN_CODE, TIME_EXTRN_CODE ORDER BY LINE_NUM) rnf  FROM TIER1_FACT_MTRLZ_TBL mfct\\n),\\nwrg AS ( \\nSELECT * FROM (SELECT /*+ parallel(8) */ * FROM ordf\\nWHERE NOT(\\nREGEXP_LIKE(TRIM(FACT_AMT_1), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_2), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_3), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_4), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_5), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_6), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_7), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_8), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_9), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_10), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_11), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_12), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_13), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_14), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_15), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_16), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_17), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_18), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_19), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_20), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n  )\\n )\\n WHERE limit  100\\n) \\n       \\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST, \\nwrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME,\\nFACT_AMT_1 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=1)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=21) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=41) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=61) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=81) \\nEND AS MEASURE\\nFROM wrg \\nLEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE\\nLEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE\\nLEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE\\nWHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_1), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  \\nwrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, \\nFACT_AMT_2 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=2)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=22) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=42) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=62) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=82) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_2), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_3 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=3)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=23) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=43) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=63) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=83) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_3), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_4 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=4)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=24) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=44) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=64) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=84) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_4), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_5 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=5)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=25) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=45) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=65) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=85) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_5), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_6 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=6)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=26) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=46) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=66) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=86) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_6), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_7 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=7)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=27) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=47) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=67) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=87) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_7), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_8 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=8)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=28) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=48) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=68) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=88) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_8), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_9 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=9)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=29) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=49) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=69) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=89) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_9), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_10 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=10)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=30) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=50) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=70) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=90) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_10), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_11 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=11)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=31) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=51) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=71) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=91) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_11), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_12 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=12)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=32) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=52) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=72) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=92) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_12), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_13 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=13)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=33) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=53) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=73)\\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=93) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_13), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_14 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=14)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=34) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=54) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=74) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=94) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_14), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_15 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=15)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=35) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=55) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=75) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=95) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_15), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_16 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=16)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=36) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=56) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=76) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=96) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_16), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_17 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=17)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=37) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=57) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=77) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=97) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_17), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_18 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=18)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=38) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=58) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=78) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=98) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_18), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_19 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=19)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=39) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=59) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=79) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=99) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_19), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_20 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=20)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=40) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=60) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=80) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=100) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_20), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$'))\\n \\nORDER BY LINE_NUM\\\"\\\"\\\"\\n\\ndf_val1 = spark.sql(rpt_query1)\\n\\n#2. Duplicated market attributes in the input file\\n\\n\\n#rpt_query2 = \\\"\\\"\\\" SELECT ('Duplicated market attributes in the input file') DQ, * FROM (SELECT DISTINCT A.LINE_NUM AS LINE_NUM,\\n#A.EXTRN_CODE as EXTRN_CODE,\\n#A.EXTRN_MKT_ATTR_VAL_LIST AS EXTRN_MKT_ATTR_VAL_LIST,\\n#A.EXTRN_NAME AS EXTRN_NAME\\n#    FROM TIER1_MKT_MTRLZ_TBL A JOIN TIER1_MKT_MTRLZ_TBL B \\n#    ON A.EXTRN_MKT_ATTR_VAL_LIST = B.EXTRN_MKT_ATTR_VAL_LIST\\n#    AND A.LINE_NUM != B.LINE_NUM\\n#\\tORDER BY EXTRN_MKT_ATTR_VAL_LIST, LINE_NUM)\\\"\\\"\\\"\\n# \\n#df_val2 = spark.sql(rpt_query2)\\n\\n#3. Duplicated market code in the input file\\n\\n#Report\\n\\nrpt_query3 = \\\"\\\"\\\"SELECT ('Duplicated market code in the input file') DQ, * FROM (SELECT DISTINCT A.LINE_NUM AS LINE_NUM,\\nA.EXTRN_CODE AS EXTRN_CODE,\\nA.EXTRN_NAME AS EXTRN_NAME\\n    FROM TIER1_MKT_MTRLZ_TBL A JOIN TIER1_MKT_MTRLZ_TBL B \\n    ON A.EXTRN_CODE = B.EXTRN_CODE\\n    AND A.LINE_NUM != B.LINE_NUM)\\n    \\n\\tORDER BY LINE_NUM  \\\"\\\"\\\"\\ndf_val3 = spark.sql(rpt_query3)\\n\\n#4. Duplicated measure in the input file\\n\\n#Report\\nrpt_query4 = \\\"\\\"\\\"SELECT ('Duplicated measure in the input file') DQ,* FROM (SELECT DISTINCT A.LINE_NUM AS LINE_NUM,\\nA.EXTRN_CODE AS EXTRN_CODE,\\nA.EXTRN_NAME AS EXTRN_NAME\\n    FROM TIER1_MEASR_MTRLZ_TBL A JOIN TIER1_MEASR_MTRLZ_TBL B \\n    ON A.EXTRN_CODE = B.EXTRN_CODE\\n    AND A.LINE_NUM != B.LINE_NUM)\\n\\tORDER BY LINE_NUM \\\"\\\"\\\"\\n\\ndf_val4 = spark.sql(rpt_query4)\\n\\n#5. Duplicated product attributes in the input file\\n#Report\\nrpt_query5 = \\\"\\\"\\\"\\nSELECT * FROM (\\n     WITH PROD_LVL AS (\\n                           SELECT  categ_id,\\ncast(strct_num as string) strct_num,\\nstrct_code,\\nattr_phys_name,\\nigrtd_layer_attr_phys_name,\\nlvl_num,\\nstrct_lvl_id,\\nattr_name,\\nattr_id\\n                            FROM MM_CATEG_STRCT_ATTR_ASSOC_VW \\n                           ),\\n     SRC AS (\\n      SELECT * FROM TIER1_PROD_MTRLZ_TBL input\\n      LEFT OUTER JOIN PROD_LVL ON input.ATTR_CODE_1 = PROD_LVL.CATEG_ID AND input.ATTR_CODE_0 = PROD_LVL.STRCT_NUM AND input.LVL_NUM = PROD_LVL.LVL_NUM                            \\n     )\\n    SELECT DISTINCT\\n    ('Duplicated product attributes in the input file') DQ,\\n    A.EXTRN_PROD_ATTR_VAL_LIST as EXTRN_PROD_ATTR_VAL_LIST,\\n    A.LINE_NUM,\\n    A.EXTRN_CODE as EXTRN_CODE,\\n    A.EXTRN_NAME as EXTRN_NAME\\n    FROM SRC A JOIN SRC B \\n    ON A.EXTRN_PROD_ATTR_VAL_LIST = B.EXTRN_PROD_ATTR_VAL_LIST\\n    AND A.LINE_NUM != B.LINE_NUM\\n\\tAND A.ATTR_NAME <> 'ITEM'\\n\\tORDER BY EXTRN_PROD_ATTR_VAL_LIST, LINE_NUM\\n    ) \\\"\\\"\\\"\\n\\ndf_val5 = spark.sql(rpt_query5)\\n\\n#6. Duplicated product code in the input file\\n\\n#Report\\n\\nrpt_query6 = \\\"\\\"\\\"SELECT ('Duplicated product code in the input file') DQ, * FROM (SELECT  DISTINCT A.LINE_NUM AS LINE_NUM,\\nA.EXTRN_CODE AS EXTRN_CODE,\\nA.EXTRN_PROD_ATTR_VAL_LIST as EXTRN_PROD_ATTR_VAL_LIST,\\nA.EXTRN_NAME AS EXTRN_NAME\\n    FROM TIER1_PROD_MTRLZ_TBL A JOIN TIER1_PROD_MTRLZ_TBL B \\n    ON A.EXTRN_CODE = B.EXTRN_CODE\\n    AND A.LINE_NUM != B.LINE_NUM\\n\\tORDER BY EXTRN_CODE, LINE_NUM)\\\"\\\"\\\"\\ndf_val6 = spark.sql(rpt_query6)\\n\\n#7. Duplicated time period in the input file\\n\\n#Report\\nrpt_query7 = \\\"\\\"\\\"SELECT ('Duplicated time period in the input file') DQ, * FROM (SELECT DISTINCT A.LINE_NUM AS LINE_NUM,\\nA.EXTRN_CODE AS EXTRN_CODE,\\nA.EXTRN_NAME AS EXTRN_NAME\\n    FROM TIER1_TIME_MTRLZ_TBL A JOIN TIER1_TIME_MTRLZ_TBL B \\n    ON A.EXTRN_CODE = B.EXTRN_CODE\\n    AND A.LINE_NUM != B.LINE_NUM\\n\\t)\\n\\tORDER BY LINE_NUM  \\\"\\\"\\\"\\ndf_val7 = spark.sql(rpt_query7)\\n\\n#8. Fact data existence\\n#Report\\nrpt_query8 = \\\"\\\"\\\"WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_FACT_MTRLZ_TBL \\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Fact data existence') DQ, * from res where RESULT1 = 'FAILED' \\\"\\\"\\\"\\n\\ndf_val8 = spark.sql(rpt_query8)\\n\\n#9. Fact uses supplier market tag not defined in the reference part\\n\\n#Report\\nrpt_query9 = \\\"\\\"\\\"SELECT ('Fact uses supplier market tag not defined in the reference part') DQ, * FROM (WITH ret1 AS (\\nSELECT DISTINCT A.LINE_NUM AS LINE_MKT, A.MKT_EXTRN_CODE AS MKT_EXTRN_CODE FROM TIER1_FACT_MTRLZ_TBL A \\nLEFT JOIN TIER1_MKT_MTRLZ_TBL B ON A.MKT_EXTRN_CODE = B.EXTRN_CODE\\nWHERE B.EXTRN_CODE IS NULL \\n)\\nSELECT LINE_MKT,\\nMKT_EXTRN_CODE as MKT_EXTRN_CODE\\nFROM ret1)\\n\\nORDER BY LINE_MKT \\\"\\\"\\\"\\ndf_val9 = spark.sql(rpt_query9)\\n\\n#10. Fact uses supplier product tag not defined in the reference part\\n\\n# Report\\nrpt_query10 = \\\"\\\"\\\" SELECT ('Fact uses supplier product tag not defined in the reference part') DQ, * FROM (WITH ret2 AS (\\nSELECT DISTINCT A.LINE_NUM AS LINE_NUM, A.Prod_EXTRN_Code AS PROD_EXTRN_CODE FROM TIER1_FACT_MTRLZ_TBL A \\nLEFT JOIN TIER1_PROD_MTRLZ_TBL C ON A.Prod_EXTRN_code = C.EXTRN_CODE\\nWHERE C.EXTRN_CODE IS NULL \\n)\\nSELECT LINE_NUM,\\nPROD_EXTRN_CODE as PROD_EXTRN_CODE\\nFROM ret2)\\n\\nORDER BY LINE_NUM\\\"\\\"\\\"\\ndf_val10 = spark.sql(rpt_query10)\\n\\n#11. Fact uses supplier time tag not defined in the reference part\\n\\n#Report\\nrpt_query11 = \\\"\\\"\\\" SELECT ('Fact uses supplier time tag not defined in the reference part') DQ, * FROM (WITH ret3 AS (\\nSELECT DISTINCT A.LINE_NUM AS LINE_NUM, A.Time_EXTRN_Code AS TIME_EXTRN_CODE FROM TIER1_FACT_MTRLZ_TBL A \\nLEFT JOIN TIER1_TIME_MTRLZ_TBL D ON A.Time_EXTRN_code = D.EXTRN_CODE\\nWHERE D.EXTRN_CODE IS NULL\\n)\\nSELECT LINE_NUM,\\nTIME_EXTRN_CODE as TIME_EXTRN_CODE\\nFROM ret3)\\n\\nORDER BY LINE_NUM\\\"\\\"\\\"\\n\\ndf_val11 = spark.sql(rpt_query11)\\n\\n#12. Incorrect file format\\n\\nrpt_query12 = \\\"\\\"\\\"SELECT\\n('Incorrect file format') DQ,\\nfile_formt as file_formt,\\nline_num,\\nATTR_CODE_LIST as ATTR_CODE_LIST\\nFROM (\\nSELECT file_formt, line_num,attr_code_0||' '||attr_code_1||' '||attr_code_2||' '||attr_code_3||' '||attr_code_4||' '||attr_code_5||' '||attr_code_6||' '||attr_code_7||' '||attr_code_8||' '||attr_code_9||' '||attr_code_10 AS ATTR_CODE_LIST \\n FROM TIER1_PROD_MTRLZ_TBL src\\nJOIN mm_cntrt_tier1_atomic_vw vw\\nON src.cntrt_id = vw.cntrt_id\\nWHERE NOT REGEXP_LIKE(attr_code_0, '^\\\\\\\\\\\\d+$')\\nUNION ALL\\nSELECT file_formt, line_num,attr_code_0||' '||attr_code_1||' '||attr_code_2||' '||attr_code_3||' '||attr_code_4||' '||attr_code_5||' '||attr_code_6||' '||attr_code_7||' '||attr_code_8||' '||attr_code_9||' '||attr_code_10 AS ATTR_CODE_LIST \\n FROM TIER1_MKT_MTRLZ_TBL src\\nJOIN mm_cntrt_tier1_atomic_vw vw\\nON src.cntrt_id = vw.cntrt_id\\nWHERE NOT REGEXP_LIKE(attr_code_0, '^\\\\\\\\\\\\d+$')\\nAND strct_code = 'LF_H1')\\n\\nORDER BY LINE_NUM \\\"\\\"\\\"\\n\\ndf_val12 = spark.sql(rpt_query12)\\n\\n#13. Incorrect time period type\\n#Report\\nrpt_query13 = f\\\"\\\"\\\" \\nSELECT ('Incorrect time period type') DQ, * FROM (WITH ret3 AS (\\n    SELECT DISTINCT LINE_NUM, EXTRN_CODE,EXTRN_NAME, tpf.TIME_PERD_TYPE_CODE,\\n    CASE WHEN TIME_PERD_CLASS_CODE ='MTH' THEN 'MONTH'\\n     WHEN TIME_PERD_CLASS_CODE ='QTR' THEN 'QUARTER'\\n     WHEN TIME_PERD_CLASS_CODE ='YR' THEN 'YEAR'\\n     WHEN TIME_PERD_CLASS_CODE ='WK' THEN 'WEEK'\\n     WHEN TIME_PERD_CLASS_CODE ='CUSTM' THEN 'CUSTOM'\\n     WHEN TIME_PERD_CLASS_CODE ='BIMTH' THEN 'BI-MONTH'\\n     WHEN TIME_PERD_CLASS_CODE ='BIWK' THEN 'BI-WEEK'\\n     ELSE TIME_PERD_CLASS_CODE\\n     END\\n    AS PERD_DESC\\n\\tFROM TIER1_TIME_MTRLZ_TBL src \\n    JOIN  MM_TIME_PERD_ID_LKP map ON src.EXTRN_CODE = map.EXTRN_TIME_PERD_ID\\n    JOIN mm_time_perd_fdim_vw tpf ON tpf.TIME_PERD_ID = map.TIME_PERD_ID\\n    JOIN MM_CNTRT_TIME_PERD_TYPE_ASSOC assoc ON  assoc.CNTRT_ID = {TIER1_CNTRT_ID} \\n    WHERE map.VENDR_ID = {TIER1_VENDR_ID}\\n    AND assoc.TIME_PERD_TYPE_CODE != tpf.TIME_PERD_TYPE_CODE\\n   )\\n  SELECT LINE_NUM,\\n  EXTRN_CODE as EXTRN_CODE,\\n  EXTRN_NAME as EXTRN_NAME,\\n  TIME_PERD_TYPE_CODE as TIME_PERD_TYPE_CODE,\\n  PERD_DESC as PERD_DESC\\n  FROM ret3)\\n\\\"\\\"\\\"\\n\\ndf_val13 = spark.sql(rpt_query13)\\n\\n\\n#14. Market data existence\\n\\n#Report\\nrpt_query14 = \\\"\\\"\\\"WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_MKT_MTRLZ_TBL \\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Market data existence') DQ, * from res where RESULT1 = 'FAILED' \\\"\\\"\\\"\\ndf_val14 = spark.sql(rpt_query14)\\n\\n#15. Measure data existence\\n\\n#Report\\nrpt_query15 = \\\"\\\"\\\"WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_MEASR_MTRLZ_TBL \\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Measure data existence') DQ, * from res where RESULT1 = 'FAILED' \\\"\\\"\\\"\\ndf_val15 = spark.sql(rpt_query15)\\n\\n#16. Too many measures in the row\\n#rpt_query16 = \\\"\\\"\\\"SELECT ('Too many measures in the row') DQ, * FROM (\\n#  WITH err AS(\\n#  SELECT * FROM TIER1_FACT_MTRLZ_TBL WHERE OTHER_FCT_DATA IS NOT NULL and length(OTHER_FCT_DATA)>0\\n#  )\\n#  SELECT err.LINE_NUM,\\n#MKT_EXTRN_CODE as MKT_EXTRN_CODE,\\n#PROD_EXTRN_CODE as PROD_EXTRN_CODE,\\n#TIME_EXTRN_CODE as TIME_EXTRN_CODE,\\n#mkt.EXTRN_NAME as MKT_EXTRN_NAME,\\n#tm.EXTRN_NAME as TIME_EXTRN_NAME,\\n#prod.ATTR_CODE_LIST as ATTR_CODE_LIST,\\n#OTHER_FCT_DATA\\n\\n#  FROM err\\n#   LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON err.MKT_EXTRN_CODE = mkt.EXTRN_CODE\\n#   LEFT JOIN TIER1_TIME_MTRLZ_TBL tm ON err.TIME_EXTRN_CODE = tm.EXTRN_CODE\\n#   LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON err.PROD_EXTRN_CODE = prod.EXTRN_CODE\\n#   ) \\\"\\\"\\\"\\n#df_val16 = spark.sql(rpt_query16)\\n\\n#17. Number of fact lines does not match number of measures\\nrpt_query17 = \\\"\\\"\\\"SELECT ('Number of fact lines does not match number of measures') DQ, * FROM (SELECT\\nMKT_EXTRN_CODE as MKT_EXTRN_CODE,\\nPROD_EXTRN_CODE as PROD_EXTRN_CODE,\\nTIME_EXTRN_CODE as TIME_EXTRN_CODE\\nFROM TIER1_FACT_MTRLZ_TBL\\n    GROUP BY MKT_EXTRN_CODE, PROD_EXTRN_CODE, TIME_EXTRN_CODE\\n    HAVING COUNT(*) > (SELECT CEIL(COUNT(*)/20) FROM TIER1_MEASR_MTRLZ_TBL)) \\\"\\\"\\\"\\ndf_val17 = spark.sql(rpt_query17)\\n\\n#18. Product data existence\\n\\n# Report\\nrpt_query18 = \\\"\\\"\\\" WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_PROD_MTRLZ_TBL \\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Product data existence ') DQ, * from res where RESULT1 = 'FAILED'\\\"\\\"\\\"\\n\\ndf_val18 = spark.sql(rpt_query18)\\n\\n#19. Time data existence\\n#Report\\n\\nrpt_query19 = \\\"\\\"\\\" WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_TIME_MTRLZ_TBL\\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Time data existence') DQ, * from res where RESULT1 = 'FAILED' \\\"\\\"\\\"\\n\\ndf_val19 = spark.sql(rpt_query19)\\n\\n#20. Category in the file is matching contract specification\\n\\n#Report\\nrpt_query20 = f\\\"\\\"\\\"\\nWITH \\nc AS\\n(SELECT categ_id FROM mm_cntrt_categ_assoc c WHERE cntrt_id = {TIER1_CNTRT_ID} ),\\nret AS (\\n  SELECT line_num, attr_code_1 AS file_categ \\n  FROM TIER1_PROD_MTRLZ_TBL \\n  WHERE attr_code_1 NOT IN ( SELECT categ_id FROM c)\\n ) SELECT ('Category in the file is matching contract specification') DQ,  line_num,\\n file_categ as file_categ,\\n categ_id AS spec_categ\\n FROM ret, c \\\"\\\"\\\"\\n\\ndf_val20 = spark.sql(rpt_query20)\\n\\ndf_val = df_val1.unionByName(df_val3, True) \\\\\\n    .unionByName(df_val4, True) \\\\\\n      .unionByName(df_val5, True) \\\\\\n        .unionByName(df_val6, True) \\\\\\n          .unionByName(df_val7, True) \\\\\\n            .unionByName(df_val8, True) \\\\\\n              .unionByName(df_val9, True) \\\\\\n                .unionByName(df_val10, True) \\\\\\n                  .unionByName(df_val11, True) \\\\\\n                    .unionByName(df_val12, True) \\\\\\n                      .unionByName(df_val13, True) \\\\\\n                        .unionByName(df_val14, True) \\\\\\n                          .unionByName(df_val15, True) \\\\\\n                            .unionByName(df_val17, True) \\\\\\n                                .unionByName(df_val18, True) \\\\\\n                                  .unionByName(df_val19, True) \\\\\\n                                    .unionByName(df_val20, True)\\n\\n# Prepare KPI\\ndata = []\\n\\ndq1_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Bad fact data format' \\\",\\\"\\\",'false','Bad fact data format',100)\\ndata.append(dq1_val)\\ndq3_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Duplicated market code in the input file' \\\",\\\"\\\",'false','Duplicated market code in the input file',100)\\ndata.append(dq3_val)\\ndq4_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Duplicated measure in the input file' \\\",\\\"\\\",'false','Duplicated measure in the input file',100)\\ndata.append(dq4_val)\\ndq5_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Duplicated measure in the input file' \\\",\\\"\\\",'false','Duplicated measure in the input file',100)\\ndata.append(dq5_val)\\ndq6_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Duplicated product code in the input file' \\\",\\\"\\\",'false','Duplicated product code in the input file',100)\\ndata.append(dq6_val)\\ndq7_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Duplicated time period in the input file' \\\",\\\"\\\",'false','Duplicated time period in the input file',100)\\ndata.append(dq7_val)\\ndq8_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Fact data existence' \\\",\\\"\\\",'false','Fact data existence',100)\\ndata.append(dq8_val)\\ndq9_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Fact uses supplier market tag not defined in the reference part' \\\",\\\"\\\",'false','Fact uses supplier market tag not defined in the reference part',100)\\ndata.append(dq9_val)\\ndq10_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Fact uses supplier product tag not defined in the reference part' \\\",\\\"\\\",'false','Fact uses supplier product tag not defined in the reference part',100)\\ndata.append(dq10_val)\\ndq11_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Fact uses supplier time tag not defined in the reference part' \\\",\\\"\\\",'false','Fact uses supplier time tag not defined in the reference part',100)\\ndata.append(dq11_val)\\ndq12_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Incorrect file format' \\\",\\\"\\\",'false','Incorrect file format',100)\\ndata.append(dq12_val)\\ndq13_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Incorrect time period type' \\\",\\\"\\\",'false','Incorrect time period type',100)\\ndata.append(dq13_val)\\ndq14_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Market data existence' \\\",\\\"\\\",'false','Market data existence',100)\\ndata.append(dq14_val)\\ndq15_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Measure data existence' \\\",\\\"\\\",'false','Measure data existence',100)\\ndata.append(dq15_val)\\n#dq16_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Too many measures in the row' \\\",\\\"\\\",'false','Too many measures in the row',100)\\n#data.append(dq16_val)\\ndq17_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Number of fact lines does not match number of measures' \\\",\\\"\\\",'false','Number of fact lines does not match number of measures',100)\\ndata.append(dq17_val)\\ndq18_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Product data existence' \\\",\\\"\\\",'false','Product data existence',100)\\ndata.append(dq18_val)\\ndq19_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Time data existence' \\\",\\\"\\\",'false','Time data existence',100)\\ndata.append(dq19_val)\\ndq20_val=('DQ','SQL Validation KPI', \\\"DQ <> 'Category in the file is matching contract specification' \\\",\\\"\\\",'false','Category in the file is matching contract specification',100)\\ndata.append(dq20_val)\\n\\n#Prepare KPI Dataframe\\n\\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\\n\\nschema_for_kpi = StructType([ \\n    StructField(\\\"column\\\",StringType(),True),\\n    StructField(\\\"kpi_type\\\",StringType(),True),\\n    StructField(\\\"param_1\\\",StringType(),True),\\n    StructField(\\\"param_2\\\",StringType(),True),\\n    StructField(\\\"fail_on_error\\\",StringType(),True),\\n    StructField(\\\"check_description\\\",StringType(),True),\\n    StructField(\\\"target\\\",StringType(),True)\\n  ])\\n\\n\\ndf_file_struct_data = spark.createDataFrame(data, schema_for_kpi)\\n\\ndict_all_dfs['df_file_struct_data'] = {\\\"df_object\\\" :df_file_struct_data}\\ndf_output_dict['df_file_struct_data'] = df_file_struct_data\\n\\ndict_all_dfs['df_combine_file_struct'] = {\\\"df_object\\\" :df_val}\\ndf_output_dict['df_combine_file_struct'] = df_val\\n\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"tier1_prod_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_measr_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_mkt_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_time_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_fct_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_fct_conv\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_file_struct_data\",\n      \"cache\": \"materialize\"\n    },\n    {\n      \"name\": \"df_combine_file_struct\",\n      \"cache\": \"materialize\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": false
    },
    {
      "operationName": "[GEN] - File Structure Validation and Report Generation",
      "predecessorName": "File Structure Validations - 1.1",
      "jsonSpecification": "{\n  \"active\": \"true\",\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"true\",\n  \"customCode\": \"\\nspark = self.spark_session\\nmyLogger = self.log\\nfrom IPython import get_ipython\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\n\\nfrom pyspark.sql.functions import *\\n\\n#Variables\\n\\nTIER1_VENDR_ID=\\\"<<VENDOR_ID>>\\\"\\nTIER1_FILE_PREFX=\\\"<<CONTRACT_CODE>>\\\"\\nTIER1_CNTRT_ID=<<CNTRT_ID>>\\nTIER1_RUN_ID=<<PROCESS_RUN_KEY>>\\n\\npath = '/mnt/<@@PATH1@@>'\\n\\n# Reading tables from postgres\\n\\n\\n\\njdbcDF1 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CATEG_STRCT_ATTR_ASSOC_VW\\\")\\njdbcDF1.createOrReplaceTempView(\\\"mm_categ_strct_attr_assoc_vw\\\")\\n\\njdbcDF2 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_TIME_PERD_TYPE_ASSOC\\\")\\njdbcDF2.createOrReplaceTempView(\\\"mm_cntrt_time_perd_type_assoc\\\")\\n\\njdbcDF3 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_CATEG_ASSOC\\\")\\njdbcDF3.createOrReplaceTempView(\\\"mm_cntrt_categ_assoc\\\")\\n\\njdbcDF4 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_TIER_EXTND_VW\\\")\\njdbcDF4.createOrReplaceTempView(\\\"MM_CNTRT_TIER_EXTND_VW\\\")\\n\\nself.log(\\\"WARNING\\\",f\\\"MT: after reading jdbc 1 2 3 4\\\")\\n\\nquery_mm_cntrt_tier1_atomic_vw = \\\"\\\"\\\"select * from MM_CNTRT_TIER_EXTND_VW \\nWHERE SRCE_SYS_ID=3\\nAND CNTRT_DATA_STTUS_NAME='Production'\\nAND CNTRT_STTUS_NAME='Active'\\nAND DATA_TIER='Tier 1'\\nAND DATA_LAYER='Atomic' \\\"\\\"\\\"\\nmm_cntrt_tier1_atomic_vw = spark.sql(query_mm_cntrt_tier1_atomic_vw)\\nmm_cntrt_tier1_atomic_vw.createOrReplaceTempView('mm_cntrt_tier1_atomic_vw')\\n\\njdbcDF5 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_TIME_PERD_ID_LKP\\\")\\njdbcDF5.createOrReplaceTempView(\\\"MM_TIME_PERD_ID_LKP\\\")\\n\\njdbcDF6 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_TIME_PERD_TYPE_ASSOC\\\").filter(f\\\"cntrt_id = {TIER1_CNTRT_ID}\\\")\\njdbcDF6.createOrReplaceTempView(\\\"MM_CNTRT_TIME_PERD_TYPE_ASSOC\\\")\\n\\nself.log(\\\"WARNING\\\",f\\\"MT: after reading jdbc 5 and 6\\\")\\n\\ndf_time_perd_fdim_vw = dict_all_dfs['df_time_perd_fdim_vw'][\\\"df_object\\\"]\\ndf_time_perd_fdim_vw.createOrReplaceTempView('mm_time_perd_fdim_vw')\\n\\n#vDataframes from prior steps\\n\\ntier1_prod_mtrlz_tbl = dict_all_dfs['tier1_prod_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_measr_mtrlz_tbl = dict_all_dfs['tier1_measr_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_mkt_mtrlz_tbl = dict_all_dfs['tier1_mkt_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_time_mtrlz_tbl = dict_all_dfs['tier1_time_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_fct_mtrlz_tbl = dict_all_dfs['tier1_fct_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_fct_mtrlz_tbl2 = dict_all_dfs['tier1_fct_conv'][\\\"df_object\\\"]\\n\\n# Create views\\ntier1_prod_mtrlz_tbl.createOrReplaceTempView('tier1_prod_mtrlz_tbl')\\ntier1_measr_mtrlz_tbl.createOrReplaceTempView('tier1_measr_mtrlz_tbl')\\ntier1_mkt_mtrlz_tbl.createOrReplaceTempView('tier1_mkt_mtrlz_tbl')\\ntier1_time_mtrlz_tbl.createOrReplaceTempView('tier1_time_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl.createOrReplaceTempView('tier1_fct_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl.createOrReplaceTempView('tier1_fact_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl2.createOrReplaceTempView('tier1_fct_mtrlz_tbl2')\\n\\n# Validation work starts\\n\\n#1. Bad fact data format\\n\\n\\nrpt_query1 = \\\"\\\"\\\" SELECT \\n('Bad fact data format') DQ,\\nLINE_NUM, \\n\\tMKTEXT MKTEXT, \\n\\tMKTNAME MKTNAME, \\n\\tPRODEXT PRODEXT, \\n\\tPRODLIST PRODLIST, \\n\\tTIMEEXT TIMEEXT, \\n\\tTIMENAME TIMENAME,\\n\\terror_val error_val,\\n\\tMEASURE MEASURE \\nFROM (WITH ordm AS (\\nSELECT msr.*, ROW_NUMBER() OVER (ORDER BY LINE_NUM) rnm FROM TIER1_MEASR_MTRLZ_TBL msr \\n),\\nordf AS (\\nSELECT mfct.*, ROW_NUMBER() OVER (PARTITION BY MKT_EXTRN_CODE, PROD_EXTRN_CODE, TIME_EXTRN_CODE ORDER BY LINE_NUM) rnf  FROM TIER1_FACT_MTRLZ_TBL mfct\\n),\\nwrg AS ( \\nSELECT * FROM (SELECT /*+ parallel(8) */ * FROM ordf\\nWHERE NOT(\\nREGEXP_LIKE(TRIM(FACT_AMT_1), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_2), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_3), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_4), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_5), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_6), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_7), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_8), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_9), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_10), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_11), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_12), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_13), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_14), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_15), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_16), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_17), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_18), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_19), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nAND REGEXP_LIKE(TRIM(FACT_AMT_20), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n  )\\n )\\n WHERE limit  100\\n) \\n       \\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST, \\nwrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME,\\nFACT_AMT_1 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=1)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=21) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=41) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=61) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=81) \\nEND AS MEASURE\\nFROM wrg \\nLEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE\\nLEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE\\nLEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE\\nWHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_1), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  \\nwrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, \\nFACT_AMT_2 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=2)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=22) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=42) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=62) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=82) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_2), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_3 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=3)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=23) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=43) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=63) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=83) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_3), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_4 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=4)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=24) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=44) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=64) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=84) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_4), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_5 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=5)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=25) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=45) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=65) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=85) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_5), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_6 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=6)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=26) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=46) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=66) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=86) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_6), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_7 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=7)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=27) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=47) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=67) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=87) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_7), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_8 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=8)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=28) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=48) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=68) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=88) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_8), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_9 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=9)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=29) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=49) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=69) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=89) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_9), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_10 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=10)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=30) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=50) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=70) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=90) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_10), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_11 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=11)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=31) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=51) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=71) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=91) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_11), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_12 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=12)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=32) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=52) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=72) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=92) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_12), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_13 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=13)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=33) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=53) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=73)\\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=93) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_13), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_14 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=14)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=34) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=54) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=74) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=94) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_14), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_15 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=15)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=35) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=55) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=75) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=95) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_15), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_16 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=16)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=36) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=56) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=76) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=96) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_16), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_17 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=17)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=37) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=57) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=77) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=97) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_17), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\n       \\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_18 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=18)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=38) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=58) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=78) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=98) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_18), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_19 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=19)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=39) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=59) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=79) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=99) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_19), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$')\\nUNION ALL\\nSELECT wrg.LINE_NUM, wrg.MKT_EXTRN_CODE AS MKTEXT, mkt.extrn_name AS MKTNAME, wrg.Prod_EXTRN_Code AS PRODEXT, prod.attr_code_list AS PRODLIST,  wrg.Time_EXTRN_Code AS TIMEEXT,tim.EXTRN_NAME AS TIMENAME, FACT_AMT_20 AS error_val,\\nCASE \\nWHEN rnf=1 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=20)  \\nWHEN rnf=2 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=40) \\nWHEN rnf=3 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=60) \\nWHEN rnf=4 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=80) \\nWHEN rnf=5 THEN (SELECT EXTRN_NAME FROM ordm WHERE rnm=100) \\nEND AS MEASURE\\nFROM wrg  LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON wrg.MKT_EXTRN_CODE = mkt.EXTRN_CODE LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON wrg.PROD_EXTRN_CODE = prod.EXTRN_CODE LEFT JOIN TIER1_TIME_MTRLZ_TBL tim ON wrg.TIME_EXTRN_CODE = tim.EXTRN_CODE WHERE NOT REGEXP_LIKE(TRIM(FACT_AMT_20), '^-?\\\\\\\\\\\\d*(\\\\\\\\\\\\.\\\\\\\\\\\\d*)?$|^NA$|^N/A$|^N.A.$'))\\n \\nORDER BY LINE_NUM\\\"\\\"\\\"\\n\\ndf_val1 = spark.sql(rpt_query1)\\n\\n#2. Duplicated market attributes in the input file\\n\\n\\n#rpt_query2 = \\\"\\\"\\\" SELECT ('Duplicated market attributes in the input file') DQ, * FROM (SELECT DISTINCT A.LINE_NUM AS LINE_NUM,\\n#A.EXTRN_CODE as EXTRN_CODE,\\n#A.EXTRN_MKT_ATTR_VAL_LIST AS EXTRN_MKT_ATTR_VAL_LIST,\\n#A.EXTRN_NAME AS EXTRN_NAME\\n#    FROM TIER1_MKT_MTRLZ_TBL A JOIN TIER1_MKT_MTRLZ_TBL B \\n#    ON A.EXTRN_MKT_ATTR_VAL_LIST = B.EXTRN_MKT_ATTR_VAL_LIST\\n#    AND A.LINE_NUM != B.LINE_NUM\\n#\\tORDER BY EXTRN_MKT_ATTR_VAL_LIST, LINE_NUM)\\\"\\\"\\\"\\n# \\n#df_val2 = spark.sql(rpt_query2)\\n\\n#3. Duplicated market code in the input file\\n\\n#Report\\n\\nrpt_query3 = \\\"\\\"\\\"SELECT ('Duplicated market code in the input file') DQ, * FROM (SELECT DISTINCT A.LINE_NUM AS LINE_NUM,\\nA.EXTRN_CODE AS EXTRN_CODE,\\nA.EXTRN_NAME AS EXTRN_NAME\\n    FROM TIER1_MKT_MTRLZ_TBL A JOIN TIER1_MKT_MTRLZ_TBL B \\n    ON A.EXTRN_CODE = B.EXTRN_CODE\\n    AND A.LINE_NUM != B.LINE_NUM)\\n    \\n\\tORDER BY LINE_NUM  \\\"\\\"\\\"\\ndf_val3 = spark.sql(rpt_query3)\\n\\n#4. Duplicated measure in the input file\\n\\n#Report\\nrpt_query4 = \\\"\\\"\\\"SELECT ('Duplicated measure in the input file') DQ,* FROM (SELECT DISTINCT A.LINE_NUM AS LINE_NUM,\\nA.EXTRN_CODE AS EXTRN_CODE,\\nA.EXTRN_NAME AS EXTRN_NAME\\n    FROM TIER1_MEASR_MTRLZ_TBL A JOIN TIER1_MEASR_MTRLZ_TBL B \\n    ON A.EXTRN_CODE = B.EXTRN_CODE\\n    AND A.LINE_NUM != B.LINE_NUM)\\n\\tORDER BY LINE_NUM \\\"\\\"\\\"\\n\\ndf_val4 = spark.sql(rpt_query4)\\n\\n#5. Duplicated product attributes in the input file\\n#Report\\nrpt_query5 = \\\"\\\"\\\"\\nSELECT * FROM (\\n     WITH PROD_LVL AS (\\n                           SELECT  categ_id,\\ncast(strct_num as string) strct_num,\\nstrct_code,\\nattr_phys_name,\\nigrtd_layer_attr_phys_name,\\nlvl_num,\\nstrct_lvl_id,\\nattr_name,\\nattr_id\\n                            FROM MM_CATEG_STRCT_ATTR_ASSOC_VW \\n                           ),\\n     SRC AS (\\n      SELECT * FROM TIER1_PROD_MTRLZ_TBL input\\n      LEFT OUTER JOIN PROD_LVL ON input.ATTR_CODE_1 = PROD_LVL.CATEG_ID AND input.ATTR_CODE_0 = PROD_LVL.STRCT_NUM AND input.LVL_NUM = PROD_LVL.LVL_NUM                            \\n     )\\n    SELECT DISTINCT\\n    ('Duplicated product attributes in the input file') DQ,\\n    A.EXTRN_PROD_ATTR_VAL_LIST as EXTRN_PROD_ATTR_VAL_LIST,\\n    A.LINE_NUM,\\n    A.EXTRN_CODE as EXTRN_CODE,\\n    A.EXTRN_NAME as EXTRN_NAME\\n    FROM SRC A JOIN SRC B \\n    ON A.EXTRN_PROD_ATTR_VAL_LIST = B.EXTRN_PROD_ATTR_VAL_LIST\\n    AND A.LINE_NUM != B.LINE_NUM\\n\\tAND A.ATTR_NAME <> 'ITEM'\\n\\tORDER BY EXTRN_PROD_ATTR_VAL_LIST, LINE_NUM\\n    ) \\\"\\\"\\\"\\n\\ndf_val5 = spark.sql(rpt_query5)\\n\\n#6. Duplicated product code in the input file\\n\\n#Report\\n\\nrpt_query6 = \\\"\\\"\\\"SELECT ('Duplicated product code in the input file') DQ, * FROM (SELECT  DISTINCT A.LINE_NUM AS LINE_NUM,\\nA.EXTRN_CODE AS EXTRN_CODE,\\nA.EXTRN_PROD_ATTR_VAL_LIST as EXTRN_PROD_ATTR_VAL_LIST,\\nA.EXTRN_NAME AS EXTRN_NAME\\n    FROM TIER1_PROD_MTRLZ_TBL A JOIN TIER1_PROD_MTRLZ_TBL B \\n    ON A.EXTRN_CODE = B.EXTRN_CODE\\n    AND A.LINE_NUM != B.LINE_NUM\\n\\tORDER BY EXTRN_CODE, LINE_NUM)\\\"\\\"\\\"\\ndf_val6 = spark.sql(rpt_query6)\\n\\n#7. Duplicated time period in the input file\\n\\n#Report\\nrpt_query7 = \\\"\\\"\\\"SELECT ('Duplicated time period in the input file') DQ, * FROM (SELECT DISTINCT A.LINE_NUM AS LINE_NUM,\\nA.EXTRN_CODE AS EXTRN_CODE,\\nA.EXTRN_NAME AS EXTRN_NAME\\n    FROM TIER1_TIME_MTRLZ_TBL A JOIN TIER1_TIME_MTRLZ_TBL B \\n    ON A.EXTRN_CODE = B.EXTRN_CODE\\n    AND A.LINE_NUM != B.LINE_NUM\\n\\t)\\n\\tORDER BY LINE_NUM  \\\"\\\"\\\"\\ndf_val7 = spark.sql(rpt_query7)\\n\\n#8. Fact data existence\\n#Report\\nrpt_query8 = \\\"\\\"\\\"WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_FACT_MTRLZ_TBL \\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Fact data existence') DQ, * from res where RESULT1 = 'FAILED' \\\"\\\"\\\"\\n\\ndf_val8 = spark.sql(rpt_query8)\\n\\n#9. Fact uses supplier market tag not defined in the reference part\\n\\n#Report\\nrpt_query9 = \\\"\\\"\\\"SELECT ('Fact uses supplier market tag not defined in the reference part') DQ, * FROM (WITH ret1 AS (\\nSELECT DISTINCT A.LINE_NUM AS LINE_MKT, A.MKT_EXTRN_CODE AS MKT_EXTRN_CODE FROM TIER1_FACT_MTRLZ_TBL A \\nLEFT JOIN TIER1_MKT_MTRLZ_TBL B ON A.MKT_EXTRN_CODE = B.EXTRN_CODE\\nWHERE B.EXTRN_CODE IS NULL \\n)\\nSELECT LINE_MKT,\\nMKT_EXTRN_CODE as MKT_EXTRN_CODE\\nFROM ret1)\\n\\nORDER BY LINE_MKT \\\"\\\"\\\"\\ndf_val9 = spark.sql(rpt_query9)\\n\\n#10. Fact uses supplier product tag not defined in the reference part\\n\\n# Report\\nrpt_query10 = \\\"\\\"\\\" SELECT ('Fact uses supplier product tag not defined in the reference part') DQ, * FROM (WITH ret2 AS (\\nSELECT DISTINCT A.LINE_NUM AS LINE_NUM, A.Prod_EXTRN_Code AS PROD_EXTRN_CODE FROM TIER1_FACT_MTRLZ_TBL A \\nLEFT JOIN TIER1_PROD_MTRLZ_TBL C ON A.Prod_EXTRN_code = C.EXTRN_CODE\\nWHERE C.EXTRN_CODE IS NULL \\n)\\nSELECT LINE_NUM,\\nPROD_EXTRN_CODE as PROD_EXTRN_CODE\\nFROM ret2)\\n\\nORDER BY LINE_NUM\\\"\\\"\\\"\\ndf_val10 = spark.sql(rpt_query10)\\n\\n#11. Fact uses supplier time tag not defined in the reference part\\n\\n#Report\\nrpt_query11 = \\\"\\\"\\\" SELECT ('Fact uses supplier time tag not defined in the reference part') DQ, * FROM (WITH ret3 AS (\\nSELECT DISTINCT A.LINE_NUM AS LINE_NUM, A.Time_EXTRN_Code AS TIME_EXTRN_CODE FROM TIER1_FACT_MTRLZ_TBL A \\nLEFT JOIN TIER1_TIME_MTRLZ_TBL D ON A.Time_EXTRN_code = D.EXTRN_CODE\\nWHERE D.EXTRN_CODE IS NULL\\n)\\nSELECT LINE_NUM,\\nTIME_EXTRN_CODE as TIME_EXTRN_CODE\\nFROM ret3)\\n\\nORDER BY LINE_NUM\\\"\\\"\\\"\\n\\ndf_val11 = spark.sql(rpt_query11)\\n\\n#12. Incorrect file format\\n\\nrpt_query12 = \\\"\\\"\\\"SELECT\\n('Incorrect file format') DQ,\\nfile_formt as file_formt,\\nline_num,\\nATTR_CODE_LIST as ATTR_CODE_LIST\\nFROM (\\nSELECT file_formt, line_num,attr_code_0||' '||attr_code_1||' '||attr_code_2||' '||attr_code_3||' '||attr_code_4||' '||attr_code_5||' '||attr_code_6||' '||attr_code_7||' '||attr_code_8||' '||attr_code_9||' '||attr_code_10 AS ATTR_CODE_LIST \\n FROM TIER1_PROD_MTRLZ_TBL src\\nJOIN mm_cntrt_tier1_atomic_vw vw\\nON src.cntrt_id = vw.cntrt_id\\nWHERE NOT REGEXP_LIKE(attr_code_0, '^\\\\\\\\\\\\d+$')\\nUNION ALL\\nSELECT file_formt, line_num,attr_code_0||' '||attr_code_1||' '||attr_code_2||' '||attr_code_3||' '||attr_code_4||' '||attr_code_5||' '||attr_code_6||' '||attr_code_7||' '||attr_code_8||' '||attr_code_9||' '||attr_code_10 AS ATTR_CODE_LIST \\n FROM TIER1_MKT_MTRLZ_TBL src\\nJOIN mm_cntrt_tier1_atomic_vw vw\\nON src.cntrt_id = vw.cntrt_id\\nWHERE NOT REGEXP_LIKE(attr_code_0, '^\\\\\\\\\\\\d+$')\\nAND strct_code = 'LF_H1')\\n\\nORDER BY LINE_NUM \\\"\\\"\\\"\\n\\ndf_val12 = spark.sql(rpt_query12)\\n\\n#13. Incorrect time period type\\n#Report\\nrpt_query13 = f\\\"\\\"\\\" \\nSELECT ('Incorrect time period type') DQ, * FROM (WITH ret3 AS (\\n    SELECT DISTINCT LINE_NUM, EXTRN_CODE,EXTRN_NAME, tpf.TIME_PERD_TYPE_CODE,\\n    CASE WHEN TIME_PERD_CLASS_CODE ='MTH' THEN 'MONTH'\\n     WHEN TIME_PERD_CLASS_CODE ='QTR' THEN 'QUARTER'\\n     WHEN TIME_PERD_CLASS_CODE ='YR' THEN 'YEAR'\\n     WHEN TIME_PERD_CLASS_CODE ='WK' THEN 'WEEK'\\n     WHEN TIME_PERD_CLASS_CODE ='CUSTM' THEN 'CUSTOM'\\n     WHEN TIME_PERD_CLASS_CODE ='BIMTH' THEN 'BI-MONTH'\\n     WHEN TIME_PERD_CLASS_CODE ='BIWK' THEN 'BI-WEEK'\\n     ELSE TIME_PERD_CLASS_CODE\\n     END\\n    AS PERD_DESC\\n\\tFROM TIER1_TIME_MTRLZ_TBL src \\n    JOIN  MM_TIME_PERD_ID_LKP map ON src.EXTRN_CODE = map.EXTRN_TIME_PERD_ID\\n    JOIN mm_time_perd_fdim_vw tpf ON tpf.TIME_PERD_ID = map.TIME_PERD_ID\\n    JOIN MM_CNTRT_TIME_PERD_TYPE_ASSOC assoc ON  assoc.CNTRT_ID = {TIER1_CNTRT_ID} \\n    WHERE map.VENDR_ID = {TIER1_VENDR_ID}\\n    AND assoc.TIME_PERD_TYPE_CODE != tpf.TIME_PERD_TYPE_CODE\\n   )\\n  SELECT LINE_NUM,\\n  EXTRN_CODE as EXTRN_CODE,\\n  EXTRN_NAME as EXTRN_NAME,\\n  TIME_PERD_TYPE_CODE as TIME_PERD_TYPE_CODE,\\n  PERD_DESC as PERD_DESC\\n  FROM ret3)\\n\\\"\\\"\\\"\\n\\ndf_val13 = spark.sql(rpt_query13)\\n\\n\\n#14. Market data existence\\n\\n#Report\\nrpt_query14 = \\\"\\\"\\\"WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_MKT_MTRLZ_TBL \\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Market data existence') DQ, * from res where RESULT1 = 'FAILED' \\\"\\\"\\\"\\ndf_val14 = spark.sql(rpt_query14)\\n\\n#15. Measure data existence\\n\\n#Report\\nrpt_query15 = \\\"\\\"\\\"WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_MEASR_MTRLZ_TBL \\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Measure data existence') DQ, * from res where RESULT1 = 'FAILED' \\\"\\\"\\\"\\ndf_val15 = spark.sql(rpt_query15)\\n\\n#16. Too many measures in the row\\n#rpt_query16 = \\\"\\\"\\\"SELECT ('Too many measures in the row') DQ, * FROM (\\n#  WITH err AS(\\n#  SELECT * FROM TIER1_FACT_MTRLZ_TBL WHERE OTHER_FCT_DATA IS NOT NULL and length(OTHER_FCT_DATA)>0\\n#  )\\n#  SELECT err.LINE_NUM,\\n#MKT_EXTRN_CODE as MKT_EXTRN_CODE,\\n#PROD_EXTRN_CODE as PROD_EXTRN_CODE,\\n#TIME_EXTRN_CODE as TIME_EXTRN_CODE,\\n#mkt.EXTRN_NAME as MKT_EXTRN_NAME,\\n#tm.EXTRN_NAME as TIME_EXTRN_NAME,\\n#prod.ATTR_CODE_LIST as ATTR_CODE_LIST,\\n#OTHER_FCT_DATA\\n\\n#  FROM err\\n#   LEFT JOIN TIER1_MKT_MTRLZ_TBL mkt ON err.MKT_EXTRN_CODE = mkt.EXTRN_CODE\\n#   LEFT JOIN TIER1_TIME_MTRLZ_TBL tm ON err.TIME_EXTRN_CODE = tm.EXTRN_CODE\\n#   LEFT JOIN TIER1_PROD_MTRLZ_TBL prod ON err.PROD_EXTRN_CODE = prod.EXTRN_CODE\\n#   ) \\\"\\\"\\\"\\n#df_val16 = spark.sql(rpt_query16)\\n\\n#17. Number of fact lines does not match number of measures\\nrpt_query17 = \\\"\\\"\\\"SELECT ('Number of fact lines does not match number of measures') DQ, * FROM (SELECT\\nMKT_EXTRN_CODE as MKT_EXTRN_CODE,\\nPROD_EXTRN_CODE as PROD_EXTRN_CODE,\\nTIME_EXTRN_CODE as TIME_EXTRN_CODE\\nFROM TIER1_FACT_MTRLZ_TBL\\n    GROUP BY MKT_EXTRN_CODE, PROD_EXTRN_CODE, TIME_EXTRN_CODE\\n    HAVING COUNT(*) > (SELECT CEIL(COUNT(*)/20) FROM TIER1_MEASR_MTRLZ_TBL)) \\\"\\\"\\\"\\ndf_val17 = spark.sql(rpt_query17)\\n\\n#18. Product data existence\\n\\n# Report\\nrpt_query18 = \\\"\\\"\\\" WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_PROD_MTRLZ_TBL \\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Product data existence ') DQ, * from res where RESULT1 = 'FAILED'\\\"\\\"\\\"\\n\\ndf_val18 = spark.sql(rpt_query18)\\n\\n#19. Time data existence\\n#Report\\n\\nrpt_query19 = \\\"\\\"\\\" WITH \\n  ret AS ( \\n    SELECT COUNT(*) AS NR FROM TIER1_TIME_MTRLZ_TBL\\n  ),\\nres(SELECT\\nCASE WHEN NR = 0 THEN 'FAILED'  END AS RESULT1 from ret)\\nselect ('Time data existence') DQ, * from res where RESULT1 = 'FAILED' \\\"\\\"\\\"\\n\\ndf_val19 = spark.sql(rpt_query19)\\n\\n#20. Category in the file is matching contract specification\\n\\n#Report\\nrpt_query20 = f\\\"\\\"\\\"\\nWITH \\nc AS\\n(SELECT categ_id FROM mm_cntrt_categ_assoc c WHERE cntrt_id = {TIER1_CNTRT_ID} ),\\nret AS (\\n  SELECT line_num, attr_code_1 AS file_categ \\n  FROM TIER1_PROD_MTRLZ_TBL \\n  WHERE attr_code_1 NOT IN ( SELECT categ_id FROM c)\\n ) SELECT ('Category in the file is matching contract specification') DQ,  line_num,\\n file_categ as file_categ,\\n categ_id AS spec_categ\\n FROM ret, c \\\"\\\"\\\"\\n\\ndf_val20 = spark.sql(rpt_query20)\\n\\ndf_val = df_val1.unionByName(df_val3, True) \\\\\\n    .unionByName(df_val4, True) \\\\\\n      .unionByName(df_val5, True) \\\\\\n        .unionByName(df_val6, True) \\\\\\n          .unionByName(df_val7, True) \\\\\\n            .unionByName(df_val8, True) \\\\\\n              .unionByName(df_val9, True) \\\\\\n                .unionByName(df_val10, True) \\\\\\n                  .unionByName(df_val11, True) \\\\\\n                    .unionByName(df_val12, True) \\\\\\n                      .unionByName(df_val13, True) \\\\\\n                        .unionByName(df_val14, True) \\\\\\n                          .unionByName(df_val15, True) \\\\\\n                            .unionByName(df_val17, True) \\\\\\n                                .unionByName(df_val18, True) \\\\\\n                                  .unionByName(df_val19, True) \\\\\\n                                    .unionByName(df_val20, True)\\n\\n#Report Generation\\n\\nimport subprocess\\nimport os\\nimport shutil\\nimport subprocess\\nimport sys\\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\\nimport pandas as pd\\nsubprocess.check_call([sys.executable,\\\"-m\\\",\\\"pip\\\",\\\"install\\\",\\\"xlsxwriter\\\"])\\nimport xlsxwriter\\n\\nrun_id = <<PROCESS_RUN_KEY>>\\nrpt_path = '<@@PATH1@@>'\\n\\nself.log(\\\"WARNING\\\",f\\\"MT: before ExcelWriter\\\")\\n\\nwriter = pd.ExcelWriter(f'tp_dvm_rprt_{run_id}.xlsx', engine='xlsxwriter')\\n\\nself.log(\\\"WARNING\\\",f\\\"MT: after ExcelWriter\\\")\\n\\n# Prepare KPI\\ndata = []\\n\\ndq_file_val = ('File Structure Validation','','')\\ndata.append(dq_file_val)\\n\\nif df_val1.count()==0:\\n  dq1_val=('Bad fact data format', 'PASSED', '' )\\n  data.append(dq1_val)\\nelse:\\n  dq1_val=('Bad fact data format', 'FAILED', '=HYPERLINK(\\\"#FV_VAL1!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq1_val)\\n\\nif df_val3.count()==0:\\n  dq3_val=('Duplicated market code in the input file', 'PASSED', '' )\\n  data.append(dq3_val)\\nelse:\\n  dq3_val=('Duplicated market code in the input file', 'FAILED', '=HYPERLINK(\\\"#FV_VAL2!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq3_val) \\n  \\nif df_val4.count()==0:\\n  dq_val=('Duplicated measure in the input file', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Duplicated measure in the input file', 'FAILED', '=HYPERLINK(\\\"#FV_VAL3!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val) \\n  \\nif df_val5.count()==0:\\n  dq_val=('Duplicated product attributes in the input file', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Duplicated product attributes in the input file', 'FAILED', '=HYPERLINK(\\\"#FV_VAL4!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val) \\n\\nif df_val6.count()==0:\\n  dq_val=('Duplicated product code in the input file', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Duplicated product code in the input file', 'FAILED', '=HYPERLINK(\\\"#FV_VAL5!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val) \\n\\nif df_val7.count()==0:\\n  dq_val=('Duplicated time period in the input file', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Duplicated time period in the input file', 'FAILED', '=HYPERLINK(\\\"#FV_VAL6!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val) \\n  \\nif df_val8.count()==0:\\n  dq_val=('Fact data existence', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Fact data existence', 'FAILED', '=HYPERLINK(\\\"#FV_VAL7!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val) \\n\\nif df_val9.count()==0:\\n  dq_val=('Fact uses supplier market tag not defined in the reference part', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Fact uses supplier market tag not defined in the reference part', 'FAILED', '=HYPERLINK(\\\"#FV_VAL8!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val) \\n\\nif df_val10.count()==0:\\n  dq_val=('Fact uses supplier product tag not defined in the reference part', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Fact uses supplier product tag not defined in the reference part', 'FAILED', '=HYPERLINK(\\\"#FV_VAL9!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val) \\n\\nif df_val11.count()==0:\\n  dq_val=('Fact uses supplier time tag not defined in the reference part', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Fact uses supplier time tag not defined in the reference part', 'FAILED', '=HYPERLINK(\\\"#FV_VAL10!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val) \\n  \\nif df_val12.count()==0:\\n  dq_val=('Incorrect file format', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Incorrect file format', 'FAILED', '=HYPERLINK(\\\"#FV_VAL11!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val) \\n  \\nif df_val13.count()==0:\\n  dq_val=('Incorrect time period type', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Incorrect time period type', 'FAILED', '=HYPERLINK(\\\"#FV_VAL12!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val)\\n\\nif df_val14.count()==0:\\n  dq_val=('Market data existence', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Market data existence', 'FAILED', '=HYPERLINK(\\\"#FV_VAL13!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val)\\n\\nif df_val15.count()==0:\\n  dq_val=('Measure data existence', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Measure data existence', 'FAILED', '=HYPERLINK(\\\"#FV_VAL14!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val)\\nif df_val17.count()==0:\\n  dq_val=('Number of fact lines does not match number of measures', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Number of fact lines does not match number of measures', 'FAILED', '=HYPERLINK(\\\"#FV_VAL15!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val)\\n  \\nif df_val18.count()==0:\\n  dq_val=('Product data existence', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Product data existence', 'FAILED', '=HYPERLINK(\\\"#FV_VAL16!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val)\\n\\nif df_val19.count()==0:\\n  dq_val=('Time data existence', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Time data existence', 'FAILED', '=HYPERLINK(\\\"#FV_VAL17!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val)\\n  \\nif df_val20.count()==0:\\n  dq_val=('Category in the file is matching contract specification', 'PASSED', '' )\\n  data.append(dq_val)\\nelse:\\n  dq_val=('Category in the file is matching contract specification', 'FAILED', '=HYPERLINK(\\\"#FV_VAL18!A1\\\",\\\"click_here\\\")' )\\n  data.append(dq_val)\\n\\n\\n#Prepare Summary Report dataframe\\n\\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\\n\\nschema_for_kpi = StructType([ \\n    StructField(\\\"Validation\\\",StringType(),True),\\n    StructField(\\\"Result\\\",StringType(),True),\\n    StructField(\\\"Details\\\",StringType(),True)\\n  ])\\n\\n# Creation of Summary Tab\\ndf_file_struct_summary = spark.createDataFrame(data, schema_for_kpi)\\ndf_file_struct_summary= df_file_struct_summary.orderBy('Result')\\n\\nSUMMARY = df_file_struct_summary.toPandas()\\nSUMMARY.to_excel(writer,sheet_name=\\\"SUMMARY\\\",index=False)\\n\\n# Creation of other tabs\\n\\nlst_dfs = [df_val1, df_val3, df_val4, df_val5, df_val6, df_val7,df_val8,df_val9,df_val10,df_val11,df_val12,df_val13,df_val14,df_val15,df_val17,df_val18,df_val19,df_val20]\\nc = 1\\nfor i in lst_dfs:\\n  if i.count()>0:\\n    i = i.toPandas()\\n    i.to_excel(writer,sheet_name=f\\\"FV_VAL{c}\\\",index=False)\\n  c= c+1\\n  \\nself.log(\\\"WARNING\\\",f\\\"MT: before writer close\\\")  \\n\\n# Close Excel Report and Save\\nwriter.close()\\n\\nself.log(\\\"WARNING\\\",f\\\"MT: before shutil copy\\\")\\n\\nfiles = [f for f in os.listdir('.') if os.path.isfile(f)]\\nfor f in files:\\n  if f==f'tp_dvm_rprt_{run_id}.xlsx':\\n    shutil.copyfile(f, f'/dbfs/mnt/{rpt_path}tp_dvm_rpt/tp_dvm_rprt_{run_id}_summary.xlsx')\\n    \\n\\n\\ndict_all_dfs['df_combine_file_struct'] = {\\\"df_object\\\" :df_val}\\ndf_output_dict['df_combine_file_struct'] = df_val\\n\\ndict_all_dfs['df_file_struct_summary'] = {\\\"df_object\\\" :df_file_struct_summary}\\ndf_output_dict['df_file_struct_summary'] = df_file_struct_summary\\n\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"tier1_prod_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_measr_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_mkt_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_time_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_fct_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_fct_conv\"\n    },\n    {\n      \"name\": \"df_time_perd_fdim_vw\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_combine_file_struct\",\n      \"cache\": \"materialize\"\n    },\n    {\n      \"name\": \"df_file_struct_summary\",\n      \"cache\": \"none\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": false
    },
    {
      "operationName": "Mail Sender",
      "predecessorName": "[GEN] - File Structure Validation and Report Generation",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"customCode\": \"spark = self.spark_session\\nmyLogger = self.log\\n\\nfrom IPython import get_ipython\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\nfrom pyspark.sql.functions import *\\n\\n# Run information from Postgres\\nrun_id = <<PROCESS_RUN_KEY>>\\n\\n\\n\\n# mm_process_run_lkp_vw\\nmm_process_run_lkp_vw = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/ f\\\"select * from adwgp_mm.mm_process_run_lkp_vw where run_id = {run_id}\\\")\\nmm_process_run_lkp_vw.createOrReplaceTempView('mm_process_run_lkp_vw')\\n\\nmm_process_run_lkp_vw = mm_process_run_lkp_vw.select('file_name', 'start_date_time')\\nrun_info = mm_process_run_lkp_vw.collect()\\n\\n\\n#Mail Sender\\n\\nimport smtplib\\nfrom email.mime.text import MIMEText\\nfrom email.mime.multipart import MIMEMultipart\\nfrom email.mime.base import MIMEBase\\nfrom email import encoders\\n# Setup port number and server name\\n\\nsmtp_port = 587                 # Standard secure SMTP port\\nsmtp_server = \\\"smtp.office365.com\\\"  # Google SMTP Server\\n\\ncontacts = '<<CONTACTS>>'\\n#lst_of_contacts = [i.strip() for i in contacts.split(\\\";\\\")]\\n#lst_of_contacts = [\\\"michalska.mb@pg.com\\\", \\\"ulbrych.b@pg.com\\\"]\\nlst_of_contacts = [\\\"kumtepe.o@pg.com\\\"]\\n\\n# Set up the email lists\\nemail_from = \\\"cpnotification.im@pg.com\\\"\\n\\n#email_list = [\\\"Gopi.C@lntinfotech.com\\\", \\\"jagdish.sahu@lntinfotech.com\\\", \\\"poltoratskyi.i@pg.com\\\"]\\nemail_list = [\\\"Gopi.C@lntinfotech.com\\\"]\\n\\nfor c in lst_of_contacts:\\n  email_list.append(c)\\n\\npswd = dbutils.secrets.get('tp_dpf2cdl', 'cpnotification-password')\\n\\nrun_id = <<PROCESS_RUN_KEY>>\\nfile_name = run_info[0]['file_name']\\nfile_timestamp= run_info[0]['start_date_time']\\nreport_name = f\\\"tp_dvm_rprt_{run_id}_summary.xlsx\\\"\\nrpt_path = '<@@PATH1@@>/tp_dvm_rpt/'\\n\\n# name the email subject\\nsubject = f\\\"TP File Structure DVM Validation Report for run {run_id}\\\"\\n\\n# Define the email function (dont call it email!)\\ndef send_emails(email_list):\\n\\n    for person in email_list:\\n\\n        # Make the body of the email\\n        body = f\\\"\\\"\\\"\\n\\nValidation summary:\\n\\nSource File Name: {file_name} \\n\\\\nRun id: {run_id} \\n\\nPlease find the attachments for detailed validation report\\n\\nRegards,\\nTradepanel Team    \\n        \\\"\\\"\\\"\\n        print(body)\\n        # make a MIME object to define parts of the email\\n        msg = MIMEMultipart()\\n        msg['From'] = email_from\\n        msg['To'] = person\\n        msg['Subject'] = subject\\n\\n        # Attach the body of the message\\n        msg.attach(MIMEText(body, 'plain'))\\n\\n        # Define the file to attach\\n        filename_path = f\\\"/dbfs/mnt/{rpt_path}/tp_dvm_rprt_{run_id}_summary.xlsx\\\"\\n\\n        # Open the file in python as a binary\\n        attachment= open(filename_path, 'rb')  # r for read and b for binary\\n\\n        # Encode as base 64\\n        attachment_package = MIMEBase('application', 'octet-stream')\\n        attachment_package.set_payload((attachment).read())\\n        encoders.encode_base64(attachment_package)\\n        attachment_package.add_header('Content-Disposition', \\\"attachment; filename= \\\" + report_name)\\n        msg.attach(attachment_package)\\n\\n        # Cast as string\\n        text = msg.as_string()\\n\\n        # Connect with the server\\n        print(\\\"Connecting to server...\\\")\\n        TIE_server = smtplib.SMTP(smtp_server, smtp_port)\\n        TIE_server.starttls()\\n        TIE_server.login(email_from, pswd)\\n        print(\\\"Succesfully connected to server\\\")\\n        print()\\n\\n\\n        # Send emails to \\\"person\\\" as list is iterated\\n        print(f\\\"Sending email to: {person}...\\\")\\n        TIE_server.sendmail(email_from, person, text)\\n        print(f\\\"Email sent to: {person}\\\")\\n        print()\\n\\n    # Close the port\\n    TIE_server.quit()\\n\\n\\n# Run the function\\nsend_emails(email_list)\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_file_struct_summary\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_file_struct_summary\",\n      \"cache\": \"none\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": false
    },
    {
      "operationName": "File Structure Validations - Union All",
      "predecessorName": "Mail Sender",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"customCode\": \"spark = self.spark_session\\nmyLogger = self.log\\nfrom IPython import get_ipython\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\n\\n\\ntier1_prod_mtrlz_tbl = dict_all_dfs['tier1_prod_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_measr_mtrlz_tbl = dict_all_dfs['tier1_measr_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_mkt_mtrlz_tbl = dict_all_dfs['tier1_mkt_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_time_mtrlz_tbl = dict_all_dfs['tier1_time_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_fct_mtrlz_tbl = dict_all_dfs['tier1_fct_mtrlz_tbl'][\\\"df_object\\\"]\\ntier1_fct_mtrlz_tbl2 = dict_all_dfs['tier1_fct_conv'][\\\"df_object\\\"]\\n\\n# Create views\\ntier1_prod_mtrlz_tbl.createOrReplaceTempView('tier1_prod_mtrlz_tbl')\\ntier1_measr_mtrlz_tbl.createOrReplaceTempView('tier1_measr_mtrlz_tbl')\\ntier1_mkt_mtrlz_tbl.createOrReplaceTempView('tier1_mkt_mtrlz_tbl')\\ntier1_time_mtrlz_tbl.createOrReplaceTempView('tier1_time_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl.createOrReplaceTempView('tier1_fct_mtrlz_tbl')\\ntier1_fct_mtrlz_tbl2.createOrReplaceTempView('tier1_fct_mtrlz_tbl2')\\n\\n# Define Variables\\nTIER1_VENDR_ID=\\\"<<VENDOR_ID>>\\\"\\nTIER1_FILE_PREFX=\\\"<<CONTRACT_CODE>>\\\"\\nTIER1_CNTRT_ID=<<CNTRT_ID>>\\nTIER1_RUN_ID=<<PROCESS_RUN_KEY>>\\n\\n# Reading tables from postgres\\n\\n\\n\\njdbcDF1 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CATEG_STRCT_ATTR_ASSOC_VW\\\")\\njdbcDF1.createOrReplaceTempView(\\\"mm_categ_strct_attr_assoc_vw\\\")\\n\\njdbcDF2 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_TIME_PERD_TYPE_ASSOC\\\")\\njdbcDF2.createOrReplaceTempView(\\\"mm_cntrt_time_perd_type_assoc\\\")\\n\\njdbcDF3 = spark.read.format(\\\"parquet\\\").load(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-lightrefined/MM_CNTRT_CATEG_ASSOC\\\")\\njdbcDF3.createOrReplaceTempView(\\\"mm_cntrt_categ_assoc\\\")\\n\\ndf_10 = spark.read.format('parquet').option('header', True).load(f'/mnt/bf/unrefined/adw-hhp-unrefined-bf/MM_TIME_PERD_FDIM_VW/')\\ndf_10.createOrReplaceTempView('mm_time_perd_fdim_vw')\\n\\n# Validations\\n\\n##prod_data_exist\\nsql1=\\\"select (1) as DQ, extrn_code as extrn_code,extrn_name as extrn_name,line_num  as line_num from tier1_prod_mtrlz_tbl limit 100\\\"\\ndf_prd_data_exist=spark.sql(sql1)\\n##measr_data_exist\\nsql2=\\\"select (2) as DQ, extrn_code as extrn_code,extrn_name as extrn_name,line_num as line_num from tier1_measr_mtrlz_tbl limit 100\\\"\\ndf_measr_data_exist=spark.sql(sql2)\\n##market_data_exist\\nsql3=\\\"select (3) as DQ, extrn_code extrn_code,attr_code_list attr_code_list,extrn_name extrn_name,line_num line_num from tier1_mkt_mtrlz_tbl limit 100\\\"\\ndf_mkt_mtrlz=spark.sql(sql3)\\n## Time data exist\\nsql4=\\\"select (4) as DQ, mm_time_perd_id as mm_time_perd_id,extrn_code as extrn_code,extrn_name as extrn_name,line_num  as line_num from tier1_time_mtrlz_tbl limit 100\\\"\\ndf_time_mtrlz=spark.sql(sql4)\\n##Fact uses supplier time tag not defined in the reference part\\nsql5=\\\"\\\"\\\"SELECT DISTINCT (5) as DQ, A.Time_extrn_Code AS time FROM  tier1_fct_mtrlz_tbl A \\nLEFT JOIN tier1_time_mtrlz_tbl D ON A.Time_extrn_code = D.EXTRN_CODE WHERE D.EXTRN_CODE IS NULL limit 100\\\"\\\"\\\"\\ndf_time_tag=spark.sql(sql5)\\n##Fact uses supplier market tag not defined in the reference part\\nsql6=\\\"\\\"\\\"SELECT DISTINCT (6) as DQ,  A.MKT_EXTRN_CODE AS market FROM tier1_fct_mtrlz_tbl A LEFT JOIN tier1_mkt_mtrlz_tbl B ON A.MKT_EXTRN_CODE= B.EXTRN_CODE  WHERE B.EXTRN_CODE IS NULL  limit 100\\\"\\\"\\\"\\ndf_mkt_tag=spark.sql(sql6)\\n##Check whether in the reference part of the file multiple lines with the same product tag exist\\nsql7=\\\"\\\"\\\"SELECT DISTINCT (7) as DQ,  A.Prod_extrn_Code AS prod FROM tier1_fct_mtrlz_tbl A LEFT JOIN tier1_prod_mtrlz_tbl C ON A.Prod_extrn_code = C.EXTRN_CODE  WHERE C.EXTRN_CODE IS NULL limit 100\\\"\\\"\\\"\\ndf_prod_tag=spark.sql(sql7)\\n##Check whether in the reference part of the file multiple lines with the same product attribute exist\\nsql8=\\\"\\\"\\\"WITH PROD_LVL AS (SELECT  * FROM mm_categ_strct_attr_assoc_vw ),\\nSRC AS (\\nSELECT * FROM tier1_prod_mtrlz_tbl input\\n LEFT OUTER JOIN PROD_LVL ON input.ATTR_CODE_1 = PROD_LVL.CATEG_ID AND input.ATTR_CODE_0 = cast(PROD_LVL.STRCT_NUM as string) AND input.LVL_NUM = PROD_LVL.LVL_NUM                            \\n)\\nSELECT (8) as DQ, A.EXTRN_PROD_ATTR_VAL_LIST as extrn_prod_attr_val_list FROM SRC A JOIN SRC B \\nON A.EXTRN_PROD_ATTR_VAL_LIST = B.EXTRN_PROD_ATTR_VAL_LIST AND A.LINE_NUM != B.LINE_NUM AND A.ATTR_NAME <> 'ITEM' limit 100\\\"\\\"\\\"\\ndf_prod_attr_tag=spark.sql(sql8)\\n##Check whether in the reference part of the file multiple lines with the same measure tag exist(Found in rprt prc)\\nsql9=\\\"\\\"\\\"SELECT DISTINCT (9) as DQ,  A.LINE_NUM AS line_num,(A.EXTRN_CODE) AS extrn_code,(A.EXTRN_NAME) AS extrn_name FROM tier1_measr_mtrlz_tbl A JOIN tier1_measr_mtrlz_tbl B ON A.EXTRN_CODE = B.EXTRN_CODE AND A.LINE_NUM != B.LINE_NUM\\\"\\\"\\\"\\ndf_measr_tag=spark.sql(sql9)\\n##Check if values of all facts delivered are valid numbers or are NA or blanks\\nsql10=\\\"\\\"\\\"SELECT (10) as DQ, mkt_extrn_code as mkt_extrn_code,prod_extrn_code as prod_extrn_code,time_extrn_code as time_extrn_code, fact_amt_1 as fact_amt_1 FROM tier1_fct_mtrlz_tbl limit 100\\\"\\\"\\\"\\ndf_vld_NA=spark.sql(sql10)\\n##The maximum number of measures in the file in one fact line is 20\\n#sql11=\\\"\\\"\\\"SELECT (11) as DQ, mkt_extrn_code as mkt_extrn_code,prod_extrn_code as prod_extrn_code,time_extrn_code as time_extrn_code, OTHER_FCT_DATA as fact_amt FROM tier1_fct_mtrlz_tbl2 WHERE OTHER_FCT_DATA IS NOT NULL LIMIT 100\\\"\\\"\\\"\\n#df_measr_fct_line=spark.sql(sql11)\\n##Tests whether at least a single line with fact dimension is available\\n#sql12=\\\"\\\"\\\"SELECT (12) as DQ, mkt_extrn_code as mkt_extrn_code,prod_extrn_code as prod_extrn_code,time_extrn_code as time_extrn_code FROM tier1_fct_mtrlz_tbl2 WHERE OTHER_FCT_DATA IS NOT NULL LIMIT 100\\\"\\\"\\\"\\n#df_fct_mtrlz=spark.sql(sql12)\\n##Number of fact lines per each combination of tags should equal total number of measures in reference part divided by expected number of measures in a single fact line i.e. by 20\\nsql13=\\\"\\\"\\\"SELECT (13) as DQ, extrn_code as extrn_code,attr_code_list as attr_code_list ,mkt_match_attr_list as mkt_match_attr_list ,extrn_mkt_attr_val_list as extrn_mkt_attr_val_list,attr_code_0 as attr_code_0 FROM tier1_mkt_mtrlz_tbl WHERE (ATTR_CODE_0 <> '1' OR ATTR_CODE_0 IS NULL) AND STRCT_CODE NOT LIKE 'TP%' limit 100\\\"\\\"\\\"\\ndf_divi_measr=spark.sql(sql13)\\n##checks whether supplier tags for market dimensions in each fact line are defined in the reference part\\nsql14=\\\"\\\"\\\"SELECT DISTINCT (14) as DQ,  A.LINE_NUM AS line_mkt, A.MKT_EXTRN_CODE AS mkt_extrn_code FROM tier1_fct_mtrlz_tbl2 A LEFT JOIN tier1_mkt_mtrlz_tbl B ON A.MKT_EXTRN_CODE = B.EXTRN_CODE WHERE B.EXTRN_CODE IS NULL limit 100\\\"\\\"\\\"\\ndf_multi_lines_mkt_tag=spark.sql(sql14)\\n###checks whether supplier tags for product dimension in each fact line are defined in the reference part\\nsql15=\\\"\\\"\\\"select (15) as DQ, a.prod_extrn_code as prod_extrn_code  from tier1_fct_mtrlz_tbl a left join tier1_prod_mtrlz_tbl c on a.prod_extrn_code = c.extrn_code where c.extrn_code is null  limit 100\\\"\\\"\\\"\\ndf_multilines_prod_tag=spark.sql(sql15)\\n##checks whether supplier tags for time dimension in each fact line are defined in the reference part\\nsql16=\\\"\\\"\\\"select (16) as DQ, time_extrn_code as time_extrn_code from tier1_fct_mtrlz_tbl left join tier1_time_mtrlz_tbl on  time_extrn_code==extrn_code where extrn_code is null limit 100\\\"\\\"\\\"\\ndf_multilines_time_tag=spark.sql(sql16)\\n##Delivered file format is correct vs. contract setup\\nsql17=\\\"\\\"\\\"WITH ret AS (SELECT line_num,attr_code_0 FROM tier1_prod_mtrlz_tbl WHERE NOT REGEXP_LIKE(attr_code_0, '^\\\\d+$')\\nUNION ALL\\nSELECT line_num,attr_code_0  FROM tier1_mkt_mtrlz_tbl WHERE NOT REGEXP_LIKE(attr_code_0, '^\\\\d+$') AND strct_code = 'LF_H1')    \\nselect (17) as DQ, line_num as line_num,attr_code_0 as attr_code_0 from ret limit 100\\\"\\\"\\\"\\ndf_crct_cntrct_setup=spark.sql(sql17)\\n##Tests whether category in the file is matching contract specification\\nsql18=f\\\"\\\"\\\"WITH c AS(SELECT categ_id FROM mm_cntrt_categ_assoc c WHERE cntrt_id ={TIER1_CNTRT_ID} ),\\nret AS(SELECT line_num, attr_code_1 AS file_categ FROM tier1_prod_mtrlz_tbl WHERE attr_code_1 NOT IN ( SELECT categ_id FROM c)) \\nSELECT (18) as DQ, line_num as line_num,(file_categ) as file_categ,(categ_id) AS spec_categ FROM ret, c \\\"\\\"\\\"\\ndf_file_match=spark.sql(sql18)\\n\\n# Combine Valiation Dataframes\\n\\n####################df_prod_attr_tag may thorugh error while executing \\nfrom pyspark.sql.functions import lit, row_number, monotonically_increasing_id, col, when\\nfrom pyspark.sql.window import Window\\nfrom pyspark.sql.types import *\\ncolumns = StructType([StructField('row_id', IntegerType(), True)])\\ndf_empty = spark.createDataFrame(data=[], schema=columns)\\n\\n\\ndq1 = df_prd_data_exist\\ndq2 = df_measr_data_exist\\ndq3 = df_mkt_mtrlz\\ndq4 = df_time_mtrlz\\ndq5 = df_time_tag\\ndq6 = df_mkt_tag\\ndq7 = df_prod_tag\\ndq8 = df_prod_attr_tag\\ndq9 = df_measr_tag\\ndq10 = df_vld_NA\\n# dq11 = df_measr_fct_line\\n# dq12 = df_fct_mtrlz\\ndq13 = df_divi_measr\\ndq14 = df_multi_lines_mkt_tag\\ndq15 = df_multilines_prod_tag\\ndq16 = df_multilines_time_tag\\ndq17 = df_crct_cntrct_setup\\ndq18 = df_file_match\\n\\ndf_combine = dq1.unionByName(dq2, True).unionByName(dq3, True).unionByName(dq4, True).unionByName(dq4, True).unionByName(dq6, True).unionByName(dq7, True).unionByName(dq8, True).unionByName(dq9, True).unionByName(dq10, True).unionByName(dq13, True).unionByName(dq14, True).unionByName(dq15, True).unionByName(dq16, True).unionByName(dq17, True).unionByName(dq18, True)\\n\\n\\ndata = []\\n\\ndq1_val=('DQ','SQL Validation KPI', \\\"DQ <> 1 \\\",\\\"\\\",'false','Product Data Existence',100)\\ndata.append(dq1_val)\\ndq2_val=('DQ','SQL Validation KPI', \\\"DQ <> 2 \\\",\\\"\\\",'false','Measure Data Existence',100)\\ndata.append(dq2_val)\\ndq3_val=('DQ','SQL Validation KPI', \\\"DQ <> 3 \\\",\\\"\\\",'false','Market data existence',100)\\ndata.append(dq3_val)\\ndq4_val=('DQ','SQL Validation KPI', \\\"DQ <> 4 \\\",\\\"\\\",'false','Time data existence',100)\\ndata.append(dq4_val)\\ndq5_val=('DQ','SQL Validation KPI', \\\"DQ <> 5 \\\",\\\"\\\",'false','Fact uses supplier time tag not defined in the reference part',100)\\ndata.append(dq5_val)\\ndq6_val=('DQ','SQL Validation KPI', \\\"DQ <> 6 \\\",\\\"\\\",'false','Fact uses supplier market tag not defined in the reference part',100)\\ndata.append(dq6_val)\\ndq7_val=('DQ','SQL Validation KPI', \\\"DQ <> 7 \\\",\\\"\\\",'false','Duplicated product code in the input file',100)\\ndata.append(dq7_val)\\ndq8_val=('DQ','SQL Validation KPI', \\\"DQ <> 8 \\\",\\\"\\\",'false','Duplicated product attributes in the input file',100)\\ndata.append(dq8_val)\\ndq9_val=('DQ','SQL Validation KPI', \\\"DQ <> 9 \\\",\\\"\\\",'false','Duplicated measure in the input file',100)\\ndata.append(dq9_val)\\ndq10_val=('DQ','SQL Validation KPI', \\\"DQ <> 10 \\\",\\\"\\\",'false','Bad fact data format',100)\\ndata.append(dq10_val)\\n#dq11_val=('DQ','SQL Validation KPI', \\\"DQ <> 11 \\\",\\\"\\\",'false','Too many measures in the row',100)\\n#data.append(dq11_val)\\n#dq12_val=('DQ','SQL Validation KPI', \\\"DQ <> 12 \\\",\\\"\\\",'false','Fact data existence',100)\\n#data.append(dq12_val)\\ndq13_val=('DQ','SQL Validation KPI', \\\"DQ <> 13 \\\",\\\"\\\",'false','Number of fact lines does not match number of measures',100)\\ndata.append(dq13_val)\\ndq14_val=('DQ','SQL Validation KPI', \\\"DQ <> 14 \\\",\\\"\\\",'false','Fact uses supplier market tag not defined in the reference part',100)\\ndata.append(dq14_val)\\ndq15_val=('DQ','SQL Validation KPI', \\\"DQ <> 15 \\\",\\\"\\\",'false','Fact uses supplier product tag not defined in the reference part',100)\\ndata.append(dq15_val)\\ndq16_val=('DQ','SQL Validation KPI', \\\"DQ <> 16 \\\",\\\"\\\",'false','Fact uses supplier time tag not defined in the reference part',100)\\ndata.append(dq16_val)\\ndq17_val=('DQ','SQL Validation KPI', \\\"DQ <> 17 \\\",\\\"\\\",'false','Incorrect file format',100)\\ndata.append(dq17_val)\\ndq18_val=('DQ','SQL Validation KPI', \\\"DQ <> 18 \\\",\\\"\\\",'false','Category in the file is matching contract specification',100)\\ndata.append(dq18_val)\\n\\n\\n#Prepare KPI\\n\\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\\n\\nschema_for_kpi = StructType([ \\n    StructField(\\\"column\\\",StringType(),True),\\n    StructField(\\\"kpi_type\\\",StringType(),True),\\n    StructField(\\\"param_1\\\",StringType(),True),\\n    StructField(\\\"param_2\\\",StringType(),True),\\n    StructField(\\\"fail_on_error\\\",StringType(),True),\\n    StructField(\\\"check_description\\\",StringType(),True),\\n    StructField(\\\"target\\\",StringType(),True)\\n  ])\\n\\n\\ndf_file_struct_data = spark.createDataFrame(data, schema_for_kpi)\\n\\ndict_all_dfs['df_file_struct_data'] = {\\\"df_object\\\" :df_file_struct_data}\\ndf_output_dict['df_file_struct_data'] = df_file_struct_data\\n\\ndict_all_dfs['df_combine_file_struct'] = {\\\"df_object\\\" :df_combine}\\ndf_output_dict['df_combine_file_struct'] = df_combine\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"tier1_prod_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_measr_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_mkt_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_time_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_fct_mtrlz_tbl\"\n    },\n    {\n      \"name\": \"tier1_fct_conv\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_file_struct_data\",\n      \"cache\": \"materialize\"\n    },\n    {\n      \"name\": \"df_combine_file_struct\",\n      \"cache\": \"materialize\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": false
    },
    {
      "operationName": "File Structure Checks Eligible KPIs",
      "predecessorName": "File Structure Validations - Union All",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"semaphoreOption\": \"none\",\n  \"format\": \"csv\",\n  \"disableSuccessFile\": \"false\",\n  \"shouldDeleteSuccess\": \"false\",\n  \"path\": \"bf/unrefined/adw-reference-bf/KPI/<<PROCESS_RUN_KEY>>_file.csv\",\n  \"mode\": \"overwrite\",\n  \"compression\": \"None\",\n  \"coalesceByNumber\": 1,\n  \"repartitionByColumn\": [],\n  \"columnToDrop\": [],\n  \"partitionByColumn\": [],\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_file_struct_data\"\n    }\n  ]\n}",
      "operationVersionName": "FilePublisher",
      "overridableIndicator": false
    },
    {
      "operationName": "Update Delivery Status",
      "predecessorName": "File Structure Checks Eligible KPIs",
      "jsonSpecification": "{\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"customCode\": \"spark = self.spark_session\\nfrom IPython import get_ipython\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\nimport pyspark\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.sql.types import *\\n\\n\\n\\nspark_session = SparkSession.builder.appName('Spark_Session').getOrCreate()\\n\\nrows = [['null', <<CNTRT_ID>>, <<PROCESS_RUN_KEY>>, 3, 1, 2, <<PROCESS_RUN_KEY>>]]\\n\\ncolumns = ['cmmnt_txt', 'cntrt_id', 'dlvry_id', 'dlvry_phase_id', 'dlvry_run_seq_num', 'dlvry_sttus_id', 'run_id']\\njdbcDF2 = spark_session.createDataFrame(rows, columns)\\njdbcDF2.write.format(\\\"parquet\\\").mode(\\\"append\\\").save(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-refined/MM_DLVRY_RUN_LKP\\\")\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_dummy\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_dummy\",\n      \"cache\": \"none\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": false
    },
    {
      "operationName": "File Structure Validation - DQ Check",
      "predecessorName": "Update Delivery Status",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"documentation\": \"https://jira-pg-ds.atlassian.net/wiki/spaces/CDLBOK/pages/3676897284/Turbine+DQ+Operations\",\n  \"inputType\": \"Input using uploaded file\",\n  \"path\": \"bf/unrefined/adw-reference-bf/KPI/<<PROCESS_RUN_KEY>>_file.csv\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_combine_file_struct\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_combine_file_struct_chk\",\n      \"cache\": \"materialize\"\n    }\n  ]\n}",
      "operationVersionName": "DataQualityValidation",
      "overridableIndicator": false
    },
    {
      "operationName": "Report Generation",
      "predecessorName": "File Structure Validation - DQ Check",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"documentation\": \"https://jira-pg-ds.atlassian.net/wiki/spaces/CDLBOK/pages/3676897284/Turbine+DQ+Operations\",\n  \"saveToCSV\": \"true\",\n  \"generateHTMLReport\": \"true\",\n  \"generatePDFReport\": \"false\",\n  \"includeDetailedValidationResults\": \"failed rows only\",\n  \"numberOfRowsToDisplay\": 100,\n  \"reportTemplate\": \"default\"\n}",
      "operationVersionName": "DataQualityReport",
      "overridableIndicator": false
    },
    {
      "operationName": "Stop Calc and Update Delivery Details",
      "predecessorName": "Report Generation",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"customCode\": \"spark = self.spark_session\\nmyLogger = self.log\\n\\nfrom IPython import get_ipython\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\n\\ndf = dict_all_dfs['df_combine_file_struct_chk'][\\\"df_object\\\"]\\n\\nresult = df.columns[4]\\ndf = df.withColumnRenamed(result, 'result')\\n\\nimport pyspark\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.sql.types import *\\n\\n\\n\\nspark_session = SparkSession.builder.appName('Spark_Session').getOrCreate()\\n\\n\\ncnt = df.filter(\\\"result = 'Fail' \\\" ).count()\\n\\nfrom pyspark.sql.types import StructType,StructField, StringType, IntegerType\\ndata2 = [('Pass',cnt)\\n  ]\\nschema = StructType([ \\n    StructField(\\\"result\\\",StringType(),True),\\n\\tStructField(\\\"count\\\",IntegerType(),True)\\n  ])\\n \\n\\nif (cnt>0):\\n  df\\nelse:\\n  df = spark.createDataFrame(data=data2,schema=schema)\\n\\nif (cnt>0):\\n  rows = [['null', <<CNTRT_ID>>, <<PROCESS_RUN_KEY>>, 9, 1, 4, <<PROCESS_RUN_KEY>>]]\\nelse:\\n  rows = [['null', <<CNTRT_ID>>, <<PROCESS_RUN_KEY>>, 3, 1, 3, <<PROCESS_RUN_KEY>>]]\\n\\n\\ncolumns = ['cmmnt_txt', 'cntrt_id', 'dlvry_id', 'dlvry_phase_id', 'dlvry_run_seq_num', 'dlvry_sttus_id', 'run_id']\\njdbcDF2 = spark_session.createDataFrame(rows, columns)\\njdbcDF2.write.format(\\\"parquet\\\").mode(\\\"append\\\").save(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-refined/MM_DLVRY_RUN_LKP\\\")\\n\\ndict_all_dfs['df_combine_file_struct_chk'] = {\\\"df_object\\\" :df}\\ndf_output_dict['df_combine_file_struct_chk'] = df\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_combine_file_struct_chk\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_combine_file_struct_chk\",\n      \"cache\": \"none\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": false
    },
    {
      "operationName": "Stop Calc and Update Delivery Details - 1.1",
      "predecessorName": "Stop Calc and Update Delivery Details",
      "jsonSpecification": "{\n  \"active\": \"true\",\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"customCode\": \"spark = self.spark_session\\nmyLogger = self.log\\n\\nfrom IPython import get_ipython\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\n\\ndf = dict_all_dfs['df_combine_file_struct'][\\\"df_object\\\"]\\n\\nimport pyspark\\nfrom pyspark.sql import SparkSession\\nfrom pyspark.sql.types import *\\n\\n\\n\\nspark_session = SparkSession.builder.appName('Spark_Session').getOrCreate()\\n\\n\\ncnt = df.count()\\n\\n\\nif (cnt>0):\\n  rows = [['null', <<CNTRT_ID>>, <<PROCESS_RUN_KEY>>, 9, 1, 4, <<PROCESS_RUN_KEY>>]]\\nelse:\\n  rows = [['null', <<CNTRT_ID>>, <<PROCESS_RUN_KEY>>, 3, 1, 3, <<PROCESS_RUN_KEY>>]]\\n\\n\\ncolumns = ['cmmnt_txt', 'cntrt_id', 'dlvry_id', 'dlvry_phase_id', 'dlvry_run_seq_num', 'dlvry_sttus_id', 'run_id']\\njdbcDF2 = spark_session.createDataFrame(rows, columns)\\njdbcDF2.write.format(\\\"parquet\\\").mode(\\\"append\\\").save(\\\"/mnt/refined/NNIT/tradepanel/prod-tp-refined/MM_DLVRY_RUN_LKP\\\")\\n\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_combine_file_struct\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_combine_file_struct\",\n      \"cache\": \"none\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": false
    },
    {
      "operationName": "Conditional Stop",
      "predecessorName": "Stop Calc and Update Delivery Details - 1.1",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"expression\": \"1=1\",\n  \"processStatus\": \"DQ_ISSUE\",\n  \"conditionValue\": \"true\",\n  \"milestone\": \"false\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_combine_file_struct\"\n    }\n  ]\n}",
      "operationVersionName": "ConditionalStop",
      "overridableIndicator": false
    },
    {
      "operationName": "Conditional Stop - 1.1",
      "predecessorName": "Conditional Stop",
      "jsonSpecification": "{\n  \"active\": \"true\",\n  \"expression\": \"DQ IS NOT NULL\",\n  \"processStatus\": \"DQ_ISSUE\",\n  \"conditionValue\": \"true\",\n  \"milestone\": \"false\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_combine_file_struct\"\n    }\n  ]\n}",
      "operationVersionName": "ConditionalStop",
      "overridableIndicator": false
    }
  ],
  "graphName": "t1_dq_file_structure_validation_sff"
}