{
  "applicationName": "TURBINE_INTERNAL",
  "nodes": [
    {
      "operationName": "dummySchema",
      "operationDescription": "sch",
      "jsonSpecification": "{\n  \"active\": \"true\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"false\",\n  \"manualSchema\": \"true\",\n  \"transformations\": [\n    {\n      \"columnType\": \"string\",\n      \"columnName\": \"IDS\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_1\",\n      \"cache\": \"none\"\n    }\n  ]\n}",
      "operationVersionName": "CreateSchema",
      "overridableIndicator": false
    },
    {
      "operationName": "mft_logic",
      "predecessorName": "dummySchema",
      "jsonSpecification": "{\n  \"active\": \"false\",\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"true\",\n  \"customCode\": \"spark = self.spark_session\\nimport os\\nimport pathlib\\nfrom zipfile import ZipFile\\nfrom datetime import datetime\\nfrom IPython import get_ipython\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\n\\nPK = str(<<PROCESS_RUN_KEY>>)\\n#/mnt/unrefined/NNIT/tradepanel/cloudpanel-test-unref/test/testing/testFile/raw/\\n#PK = str(12345)\\n\\ndef make_directory(filename,filepath):\\n  print(\\\"Inside make directory function\\\")\\n  initial_path = 'dbfs:/mnt/<@@RAW_PATH@@>'\\n  file_name_woextn = pathlib.Path(filepath).stem\\n  \\n  directory = initial_path + file_name_woextn\\n  dbutils.fs.mkdirs(directory)\\n  return file_name_woextn\\n  \\ndef unzip_file(localpath,file_name_woextn):\\n  print(\\\"Inside Unzip_file function\\\")\\n  print(\\\"localpath==\\\",localpath)\\n  p1 = \\\"/dbfs/mnt/<@@RAW_PATH@@>\\\"\\n  p2 = file_name_woextn\\n  p3 = p1 + p2\\n  print (\\\"unzip_path\\\",p3)\\n  with ZipFile(localpath, 'r') as zip:\\n    zip.extractall(p3)\\n    print(\\\"Unzipping Completed\\\")\\n\\t\\n\\t\\nfiles = dbutils.fs.ls('/mnt/<@@RAW_PATH@@>')\\n\\nfor fi in files:\\n  filename = fi.name\\n  filepath = fi.path\\n\\n  endwithzip = filename.endswith('.zip')\\n  endwithgz = filename.endswith('.gz')\\n  endwithcsv = filename.endswith('.csv')\\n  \\n  if ((endwithzip) and (PK in filename)): # If input file is a ZIP file\\n    print(\\\"ZIP File found\\\")\\n    localpath = os.path.join(\\\"/dbfs/mnt/<@@RAW_PATH@@>\\\", filename)\\n    \\n    # Make Directory\\n    file_name_woextn = make_directory(filename,filepath)\\n\\n    # Unzip Function\\n    unzip_file(localpath,file_name_woextn)\\n  else:\\n    print(\\\"InSide else\\\")\\n\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_1\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_2\",\n      \"cache\": \"none\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": true
    },
    {
      "operationName": "[Gen] mft_logic",
      "predecessorName": "mft_logic",
      "jsonSpecification": "{\n  \"active\": \"true\",\n  \"separateSparkSession\": \"false\",\n  \"milestone\": \"false\",\n  \"saveOutputDfsToTempTable\": \"true\",\n  \"customCode\": \"import os\\nimport shutil\\nimport os.path\\nimport pathlib\\nfrom zipfile import ZipFile\\nfrom datetime import datetime\\nfrom IPython import get_ipython\\nimport subprocess\\ndbutils = get_ipython().user_ns[\\\"dbutils\\\"]\\n \\n \\nPK = '<<PROCESS_RUN_KEY>>'\\ndef unzip_file(localpath,file_name_woextn):\\n  print(\\\"Inside Unzip_file function\\\")\\n  print(\\\"localpath==\\\",localpath)\\n  p1 = \\\"/dbfs/mnt/<@@RAW_PATH@@>\\\"\\n  p2 = file_name_woextn\\n  p3 = p1 + p2\\n  #print (\\\"unzip_path\\\",p3)\\n  #with zipfile.ZipFile(localpath, mode='r', compression=ZIP_LZMA, allowZip64=True, compresslevel=None) as zip:\\n  #  zip.extractall(p3)\\n  unzip = ['unzip','-o', localpath, '-d', p3]\\n  p = subprocess.call(unzip)\\n  print(\\\"Unzipping Completed\\\")\\n \\ndef make_directory(filename,filepath):\\n  print(\\\"Inside make directory function\\\")\\n  initial_path = 'dbfs:/mnt/<@@RAW_PATH@@>'\\n  file_name_woextn = pathlib.Path(filepath).stem\\n \\n  directory = initial_path + file_name_woextn\\n  dbutils.fs.mkdirs(directory)\\n  return file_name_woextn\\n\\ndef contains_subdirectory_with_os_walk(directory):\\n  for root, directories, files in os.walk(directory):\\n    if directories:\\n      return True\\n  return False\\n  \\nfiles = dbutils.fs.ls('/mnt/<@@RAW_PATH@@>')\\nfor fi in files:\\n  filename = fi.name\\n  filepath = fi.path\\n \\n  endwithzip = filename.endswith('.zip')\\n  endwithZIP = filename.endswith('.ZIP')\\n  endwithgz = filename.endswith('.gz')\\n  endwithcsv = filename.endswith('.csv')\\n \\n  if (((endwithzip) or (endwithZIP)) and (PK in filename)): # If input file is a ZIP file\\n    print(\\\"ZIP File found\\\")\\n    localpath = os.path.join(\\\"/dbfs/mnt/<@@RAW_PATH@@>\\\", filename)\\n    print(\\\"localpath=\\\",localpath)\\n    print(\\\"filename=\\\",filename)\\n    print(\\\"filepath=\\\",filepath)\\n    # Make Directory\\n    file_name_woextn = make_directory(filename,filepath)\\n \\n    # Unzip Function\\n    unzip_file(localpath,file_name_woextn)\\n    print(\\\"Make_Dir=\\\", file_name_woextn)\\n    rawfilepath = os.path.join(\\\"/dbfs/mnt/<@@RAW_PATH@@>\\\", file_name_woextn)\\n    directory = rawfilepath\\n    contains_subdirectory_with_os_walk(directory)\\n\\n    if contains_subdirectory_with_os_walk(directory):\\n      src = rawfilepath\\n      dest = rawfilepath\\n      for path, subdirs, files in os.walk(src):\\n        for name in files:\\n          filename = os.path.join(path, name)\\n          shutil.copy2(filename, dest)\",\n  \"inputDataframes\": [\n    {\n      \"name\": \"df_1\"\n    }\n  ],\n  \"outputDataframes\": [\n    {\n      \"name\": \"df_2\",\n      \"cache\": \"none\"\n    }\n  ]\n}",
      "operationVersionName": "Generic",
      "overridableIndicator": false
    }
  ],
  "graphName": "DPF2CDL_TradePanel_MFT"
}